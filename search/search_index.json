{"config":{"lang":["en"],"separator":"[\\s\\u200b\\-_,:!=\\[\\]()\"`/]+|\\.(?!\\d)|&[lg]t;|(?!\\b)(?=[A-Z][a-z])","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Home","text":"<ul> <li> <p> Complete Beginner Guide   Start from absolute zero. Install uv, PMCGrab, and process your first papers.</p> </li> <li> <p> Interactive Tutorial   Hands-on Jupyter notebook with real data and AI/ML examples.</p> </li> <li> <p> Quick Start   5-minute setup for experienced users.</p> </li> <li> <p> User Guide   Comprehensive guides covering every feature.</p> </li> <li> <p> API Reference   Auto-generated docs for every function and class.</p> </li> <li> <p> Examples   Real-world usage and advanced patterns.</p> </li> </ul>"},{"location":"#pmcgrab-from-pubmed-central-id-to-ai-ready-json-in-seconds","title":"PMCGrab - From PubMed Central ID to AI-Ready JSON in Seconds","text":"<p>Every AI workflow that touches biomedical literature hits the same wall:</p> <ol> <li>Download PMC XML hoping it\u2019s \u201cstructured.\u201d</li> <li>Fight nested tags, footnotes, figure refs, and half-broken links.</li> <li>Hope your regex didn\u2019t blow away the Methods section you actually need.</li> </ol> <p>PMCGrab ends this cycle. Feed the tool a list of PMC IDs and get back clean, section-aware JSON ready for embeddings, vector stores, or prompt templates.</p>"},{"location":"#example-usage","title":"Example Usage","text":"<pre><code>from pmcgrab.application.processing import process_single_pmc\n\n# Process a PMC article\ndata = process_single_pmc(\"7114487\")\n\nif data:\n    print(f\"Title: {data['title']}\")\n    print(f\"Authors: {len(data['authors'])}\")\n    print(f\"Sections: {list(data['body'].keys())}\")\n</code></pre>"},{"location":"#example-output","title":"Example Output","text":"<pre><code>{\n  \"pmc_id\": \"7114487\",\n  \"title\": \"Machine learning approaches in cancer research\",\n  \"abstract\": \"Recent advances in machine learning have revolutionized...\",\n  \"authors\": [\n    {\n      \"First_Name\": \"John\",\n      \"Last_Name\": \"Doe\",\n      \"Affiliation\": \"Cancer Research Institute\"\n    }\n  ],\n  \"body\": {\n    \"Introduction\": \"Cancer research has evolved significantly...\",\n    \"Methods\": \"We implemented a deep learning framework...\",\n    \"Results\": \"Our model achieved 94.2% accuracy...\",\n    \"Discussion\": \"These findings demonstrate the potential...\"\n  },\n  \"journal\": \"Nature Medicine\",\n  \"figures\": [...],\n  \"tables\": [...],\n  \"references\": [...]\n}\n</code></pre>"},{"location":"about/citation/","title":"Citation","text":"<p>If you use PMCGrab in your research, please cite it using the following formats:</p>"},{"location":"about/citation/#apa-style","title":"APA Style","text":"<pre><code>Mondal, R. (2025). PMCGrab: AI-ready retrieval and parsing of PubMed Central articles\nfor RAG applications (Version 0.5.7) [Computer software].\nhttps://github.com/rajdeepmondaldotcom/pmcgrab\n</code></pre>"},{"location":"about/citation/#mla-style","title":"MLA Style","text":"<pre><code>Mondal, Rajdeep. \"PMCGrab: AI-ready retrieval and parsing of PubMed Central articles\nfor RAG applications.\" GitHub, version 0.5.7, 2025,\nhttps://github.com/rajdeepmondaldotcom/pmcgrab\n</code></pre>"},{"location":"about/citation/#chicago-style","title":"Chicago Style","text":"<pre><code>Mondal, Rajdeep. \"PMCGrab: AI-ready retrieval and parsing of PubMed Central articles\nfor RAG applications.\" Version 0.5.7. Computer software. GitHub, 2025.\nhttps://github.com/rajdeepmondaldotcom/pmcgrab\n</code></pre>"},{"location":"about/citation/#bibtex","title":"BibTeX","text":"<pre><code>@software{mondal_pmcgrab_2025,\n  author = {Mondal, Rajdeep},\n  title = {PMCGrab: AI-ready retrieval and parsing of PubMed Central articles for RAG applications},\n  url = {https://github.com/rajdeepmondaldotcom/pmcgrab},\n  version = {0.5.7},\n  year = {2025}\n}\n</code></pre>"},{"location":"about/citation/#academic-papers-using-pmcgrab","title":"Academic Papers Using PMCGrab","text":"<p>If you publish research using PMCGrab, we'd love to hear about it! Please let us know by:</p> <ul> <li>Opening an issue on GitHub with your publication details</li> <li>Emailing us at rajdeep@rajdeepmondal.com</li> <li>Mentioning us on social media</li> </ul> <p>We maintain a list of academic papers and research projects that use PMCGrab to help other researchers discover relevant work.</p>"},{"location":"about/citation/#why-cite-software","title":"Why Cite Software?","text":"<p>Citing software in academic work:</p> <ul> <li>Gives proper credit to the developers and maintainers</li> <li>Enables reproducibility by specifying exact versions used</li> <li>Helps with software discovery for other researchers</li> <li>Supports the open source ecosystem by demonstrating impact</li> <li>Meets journal requirements for software citations</li> </ul>"},{"location":"about/citation/#version-information","title":"Version Information","text":"<p>When citing PMCGrab, please include:</p> <ul> <li>Version number (e.g., 0.5.7)</li> <li>Date accessed if using the latest development version</li> <li>Specific commit hash if using a development version</li> <li>DOI if available for the specific version</li> </ul> <p>You can find the version you're using with:</p> <pre><code>import pmcgrab\nprint(pmcgrab.__version__)\n</code></pre>"},{"location":"about/citation/#questions-about-citation","title":"Questions about Citation?","text":"<p>If you have questions about how to cite PMCGrab in your specific context or publication type, please:</p> <ul> <li>Check your journal's software citation guidelines</li> <li>Open an issue on GitHub for clarification</li> <li>Contact us directly for assistance</li> </ul> <p>Thank you for using PMCGrab in your research!</p>"},{"location":"about/license/","title":"License","text":"<p>PMCGrab is licensed under the Apache License 2.0.</p>"},{"location":"about/license/#apache-license-20","title":"Apache License 2.0","text":"<pre><code>Copyright 2025 Rajdeep Mondal\n\nLicensed under the Apache License, Version 2.0 (the \"License\");\nyou may not use this file except in compliance with the License.\nYou may obtain a copy of the License at\n\n    http://www.apache.org/licenses/LICENSE-2.0\n\nUnless required by applicable law or agreed to in writing, software\ndistributed under the License is distributed on an \"AS IS\" BASIS,\nWITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\nSee the License for the specific language governing permissions and\nlimitations under the License.\n</code></pre>"},{"location":"about/license/#what-this-means","title":"What this means","text":"<p>The Apache License 2.0 is a permissive license that allows you to:</p> <ul> <li>Use the software for any purpose</li> <li>Modify the software</li> <li>Distribute the software</li> <li>Patent use (license includes patent rights)</li> <li>Private use (use in private projects)</li> <li>Commercial use (use in commercial projects)</li> </ul> <p>You must:</p> <ul> <li>Include copyright (include the original copyright notice)</li> <li>Include license (include the license text)</li> <li>State changes (document any changes you make)</li> </ul> <p>You cannot:</p> <ul> <li>Hold liable (the authors cannot be held liable for damages)</li> <li>Use trademark (you cannot use the project's trademarks)</li> </ul>"},{"location":"about/license/#full-license-text","title":"Full License Text","text":"<p>For the complete license text, see the LICENSE file in the repository.</p>"},{"location":"api/cli/","title":"Command Line Interface","text":"<p>PMCGrab's command-line interface for batch processing and article retrieval.</p>"},{"location":"api/cli/#cli-module","title":"CLI Module","text":""},{"location":"api/cli/#pmcgrab.cli.pmcgrab_cli","title":"pmcgrab.cli.pmcgrab_cli","text":""},{"location":"api/cli/#pmcgrab.cli.pmcgrab_cli-functions","title":"Functions","text":""},{"location":"api/cli/#pmcgrab.cli.pmcgrab_cli.main","title":"main","text":"<pre><code>main() -&gt; None\n</code></pre> <p>Main CLI entry point for batch PMC article processing.</p> <p>Orchestrates the complete batch processing workflow: 1. Parse command-line arguments 2. Create output directory structure 3. Process PMC IDs in manageable chunks with progress tracking 4. Collect and report processing statistics 5. Write summary results to JSON file</p> <p>The function processes articles in 100-article chunks to manage memory usage and provide regular progress updates. Each chunk is processed concurrently using the specified number of worker threads.</p> Output <p>Creates individual JSON files for each successfully processed article in the output directory, plus a summary.json file containing processing statistics for all articles.</p> <p>Examples:</p> <p>This function is typically called via:     python -m pmcgrab.cli.pmcgrab_cli --pmcids 7181753 3539614</p> Note <p>The function assumes that process_pmc_ids() handles the actual file writing for individual articles. It focuses on orchestration, progress tracking, and summary generation.</p> Source code in <code>src/pmcgrab/cli/pmcgrab_cli.py</code> <pre><code>def main() -&gt; None:\n    \"\"\"Main CLI entry point for batch PMC article processing.\n\n    Orchestrates the complete batch processing workflow:\n    1. Parse command-line arguments\n    2. Create output directory structure\n    3. Process PMC IDs in manageable chunks with progress tracking\n    4. Collect and report processing statistics\n    5. Write summary results to JSON file\n\n    The function processes articles in 100-article chunks to manage memory\n    usage and provide regular progress updates. Each chunk is processed\n    concurrently using the specified number of worker threads.\n\n    Output:\n        Creates individual JSON files for each successfully processed article\n        in the output directory, plus a summary.json file containing processing\n        statistics for all articles.\n\n    Examples:\n        This function is typically called via:\n            python -m pmcgrab.cli.pmcgrab_cli --pmcids 7181753 3539614\n\n    Note:\n        The function assumes that process_pmc_ids() handles the actual file\n        writing for individual articles. It focuses on orchestration,\n        progress tracking, and summary generation.\n    \"\"\"\n    args = _parse_args()\n    pmc_ids: list[str] = args.pmcids\n    out_dir = Path(args.output_dir)\n    out_dir.mkdir(parents=True, exist_ok=True)\n\n    results = {}\n    bar = tqdm(total=len(pmc_ids), desc=\"Processing PMC IDs\", unit=\"paper\")\n    for chunk_start in range(0, len(pmc_ids), 100):\n        chunk = pmc_ids[chunk_start : chunk_start + 100]\n        chunk_results = process_pmc_ids(chunk, batch_size=args.batch_size)\n        for pid, success in chunk_results.items():\n            if success:\n                # Fetch data and write JSON\n                article_data = process_single_pmc(pid)\n                if article_data is not None:\n                    dest = out_dir / f\"PMC{pid}.json\"\n                    with dest.open(\"w\", encoding=\"utf-8\") as fh:\n                        json.dump(article_data, fh, indent=2, ensure_ascii=False)\n                else:\n                    success = False\n            results[pid] = success\n            bar.update(1)\n    bar.close()\n\n    summary_path = out_dir / \"summary.json\"\n    with open(summary_path, \"w\", encoding=\"utf-8\") as jf:\n        json.dump(results, jf, indent=2)\n    print(f\"Summary written to {summary_path}\")\n</code></pre>"},{"location":"api/cli/#usage-examples","title":"Usage Examples","text":""},{"location":"api/cli/#basic-commands","title":"Basic Commands","text":"<pre><code># Process single paper\nuv run python -m pmcgrab PMC7181753\n\n# Process multiple papers\nuv run python -m pmcgrab PMC7181753 PMC3539614 PMC5454911\n</code></pre>"},{"location":"api/cli/#advanced-options","title":"Advanced Options","text":"<pre><code># Custom output directory\nuv run python -m pmcgrab --output-dir ./results PMC7181753\n\n# Parallel processing\nuv run python -m pmcgrab --workers 8 PMC7181753 PMC3539614\n\n# From file input\nuv run python -m pmcgrab --input-file pmc_ids.txt --max-retries 3\n</code></pre>"},{"location":"api/cli/#all-options","title":"All Options","text":"<ul> <li><code>--output-dir</code>: Specify output directory (default: ./pmc_output)</li> <li><code>--workers</code>: Number of parallel workers (default: 4)</li> <li><code>--email</code>: Contact email for NCBI API</li> <li><code>--input-file</code>: Read PMC IDs from file</li> <li><code>--max-retries</code>: Maximum retry attempts for failed downloads</li> <li><code>--batch-size</code>: Number of articles per batch</li> <li><code>--timeout</code>: Request timeout in seconds</li> <li><code>--verbose</code>: Enable verbose logging</li> <li><code>--help</code>: Show help message</li> </ul>"},{"location":"api/core/","title":"Core API","text":"<p>The core API provides the main functions for processing PMC articles.</p>"},{"location":"api/core/#primary-processing-function","title":"Primary Processing Function","text":""},{"location":"api/core/#process_single_pmc","title":"process_single_pmc","text":"<p>options: show_source: true show_root_heading: true show_root_toc_entry: false show_object_full_path: false show_category_heading: false show_signature_annotations: true heading_level: 3</p>"},{"location":"api/core/#pmcgrab.application.processing.process_single_pmc","title":"pmcgrab.application.processing.process_single_pmc","text":"<pre><code>process_single_pmc(\n    pmc_id: str,\n) -&gt; dict[str, str | dict | list] | None\n</code></pre> <p>Download and parse a single PMC article into normalized dictionary format.</p> <p>Application-layer function that handles the complete processing pipeline for a single PMC article: fetching XML, parsing content, extracting structured data, and normalizing for JSON serialization. Includes timeout protection and robust error handling.</p> <p>Parameters:</p> Name Type Description Default <code>str</code> <p>String representation of the PMC ID (e.g., \"7181753\")</p> required <p>Returns:</p> Type Description <code>dict[str, str | dict | list] | None</code> <p>dict[str, str | dict | list] | None: Normalized article dictionary with keys: - pmc_id: Article identifier - title: Article title - abstract: Plain text abstract - body: Dictionary of section titles mapped to text content - authors: Normalized author information - Journal and publication metadata - Content metadata (funding, ethics, etc.)</p> <code>dict[str, str | dict | list] | None</code> <p>Returns None if processing fails or article has no usable content.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; article_data = process_single_pmc(\"7181753\")\n&gt;&gt;&gt; if article_data:\n...     print(f\"Title: {article_data['title']}\")\n...     print(f\"Sections: {list(article_data['body'].keys())}\")\n...     print(f\"Authors: {len(article_data['authors'])}\")\n</code></pre> Note <p>This function includes a 60-second timeout for network/parsing operations and performs garbage collection for memory management in batch scenarios. All values are normalized using normalize_value() for JSON compatibility.</p> Source code in <code>src/pmcgrab/application/processing.py</code> <pre><code>def process_single_pmc(pmc_id: str) -&gt; dict[str, str | dict | list] | None:\n    \"\"\"Download and parse a single PMC article into normalized dictionary format.\n\n    Application-layer function that handles the complete processing pipeline\n    for a single PMC article: fetching XML, parsing content, extracting\n    structured data, and normalizing for JSON serialization. Includes\n    timeout protection and robust error handling.\n\n    Args:\n        pmc_id: String representation of the PMC ID (e.g., \"7181753\")\n\n    Returns:\n        dict[str, str | dict | list] | None: Normalized article dictionary with keys:\n            - pmc_id: Article identifier\n            - title: Article title\n            - abstract: Plain text abstract\n            - body: Dictionary of section titles mapped to text content\n            - authors: Normalized author information\n            - Journal and publication metadata\n            - Content metadata (funding, ethics, etc.)\n        Returns None if processing fails or article has no usable content.\n\n    Examples:\n        &gt;&gt;&gt; article_data = process_single_pmc(\"7181753\")\n        &gt;&gt;&gt; if article_data:\n        ...     print(f\"Title: {article_data['title']}\")\n        ...     print(f\"Sections: {list(article_data['body'].keys())}\")\n        ...     print(f\"Authors: {len(article_data['authors'])}\")\n\n    Note:\n        This function includes a 60-second timeout for network/parsing operations\n        and performs garbage collection for memory management in batch scenarios.\n        All values are normalized using normalize_value() for JSON compatibility.\n    \"\"\"\n    gc.collect()\n    paper_info: dict[str, str | dict | list] = {}\n    body_info: dict[str, str] = {}\n\n    try:\n        pmc_id_num = int(pmc_id)\n        current_email = next_email()\n\n        # Time-boxed network / parsing\n        signal.alarm(60)\n        try:\n            paper = build_paper_from_pmc(\n                pmc_id_num, email=current_email, download=True, validate=False\n            )\n        except TimeoutException:\n            return None\n        finally:\n            signal.alarm(0)\n\n        if paper is None:\n            return None\n\n        # ---------------- Text body extraction -------------------------\n        body_sections = paper.body\n        if body_sections is not None:\n            try:\n                iter(body_sections)  # Ensure iterable\n                sec_counter = 1\n                for section in body_sections:\n                    try:\n                        text = getattr(\n                            section, \"get_section_text\", lambda s=section: str(s)\n                        )()\n                        title = (\n                            section.title\n                            if getattr(section, \"title\", None)\n                            else f\"Section {sec_counter}\"\n                        )\n                        sec_counter += 1\n                        body_info[title] = text\n                    except Exception:\n                        pass  # Robustness: ignore malformed sections\n            except (TypeError, ValueError):\n                pass\n\n        # ---------------- Assemble output dict -------------------------\n        paper_info[\"pmc_id\"] = str(pmc_id_num)\n        paper_info[\"abstract\"] = paper.abstract_as_str() if paper.abstract else \"\"\n        paper_info[\"has_data\"] = str(paper.has_data)\n        paper_info[\"body\"] = body_info or {}\n        paper_info[\"title\"] = paper.title or \"\"\n        paper_info[\"authors\"] = (\n            normalize_value(paper.authors) if paper.authors is not None else \"\"\n        )\n        paper_info[\"non_author_contributors\"] = (\n            normalize_value(paper.non_author_contributors)\n            if paper.non_author_contributors is not None\n            else \"\"\n        )\n        paper_info[\"publisher_name\"] = (\n            normalize_value(paper.publisher_name)\n            if paper.publisher_name is not None\n            else \"\"\n        )\n        paper_info[\"publisher_location\"] = (\n            normalize_value(paper.publisher_location)\n            if paper.publisher_location is not None\n            else \"\"\n        )\n        paper_info[\"article_id\"] = (\n            normalize_value(paper.article_id) if paper.article_id is not None else \"\"\n        )\n        paper_info[\"journal_title\"] = (\n            normalize_value(paper.journal_title)\n            if paper.journal_title is not None\n            else \"\"\n        )\n        paper_info[\"journal_id\"] = (\n            normalize_value(paper.journal_id) if paper.journal_id is not None else \"\"\n        )\n        paper_info[\"issn\"] = (\n            normalize_value(paper.issn) if paper.issn is not None else \"\"\n        )\n        paper_info[\"article_types\"] = (\n            normalize_value(paper.article_types)\n            if paper.article_types is not None\n            else \"\"\n        )\n        paper_info[\"article_categories\"] = (\n            normalize_value(paper.article_categories)\n            if paper.article_categories is not None\n            else \"\"\n        )\n        paper_info[\"published_date\"] = (\n            normalize_value(paper.published_date)\n            if paper.published_date is not None\n            else \"\"\n        )\n        paper_info[\"volume\"] = (\n            normalize_value(paper.volume) if paper.volume is not None else \"\"\n        )\n        paper_info[\"issue\"] = (\n            normalize_value(paper.issue) if paper.issue is not None else \"\"\n        )\n        paper_info[\"permissions\"] = (\n            normalize_value(paper.permissions) if paper.permissions is not None else \"\"\n        )\n        paper_info[\"copyright\"] = (\n            normalize_value(paper.copyright) if paper.copyright is not None else \"\"\n        )\n        paper_info[\"license\"] = (\n            normalize_value(paper.license) if paper.license is not None else \"\"\n        )\n        paper_info[\"funding\"] = (\n            normalize_value(paper.funding) if paper.funding is not None else \"\"\n        )\n        paper_info[\"footnote\"] = (\n            normalize_value(paper.footnote) if paper.footnote is not None else \"\"\n        )\n        paper_info[\"acknowledgements\"] = (\n            normalize_value(paper.acknowledgements)\n            if paper.acknowledgements is not None\n            else \"\"\n        )\n        paper_info[\"notes\"] = (\n            normalize_value(paper.notes) if paper.notes is not None else \"\"\n        )\n        paper_info[\"custom_meta\"] = (\n            normalize_value(paper.custom_meta) if paper.custom_meta is not None else \"\"\n        )\n        paper_info[\"last_updated\"] = normalize_value(getattr(paper, \"last_updated\", \"\"))\n\n        # Normalise nested structures one last time\n        paper_info = {k: normalize_value(v) for k, v in paper_info.items()}\n        if not paper_info.get(\"body\"):\n            return None\n        return paper_info\n\n    finally:\n        with contextlib.suppress(Exception):\n            del body_info, paper\n        gc.collect()\n</code></pre>"},{"location":"api/core/#pmcgrab.application.processing.process_single_pmc(pmc_id)","title":"<code>pmc_id</code>","text":""},{"location":"api/core/#email-management","title":"Email Management","text":""},{"location":"api/core/#next_email","title":"next_email","text":"<p>options: show_source: true show_root_heading: true show_root_toc_entry: false show_object_full_path: false show_category_heading: false show_signature_annotations: true heading_level: 3</p>"},{"location":"api/core/#pmcgrab.infrastructure.settings.next_email","title":"pmcgrab.infrastructure.settings.next_email","text":"<pre><code>next_email() -&gt; str\n</code></pre> <p>Return the next email address in round-robin rotation.</p> <p>Provides thread-safe access to the email pool using round-robin rotation. This ensures fair distribution of API requests across available email addresses, which helps with rate limiting and API usage policies.</p> <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>Next email address from the configured pool</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; # Get email for NCBI Entrez request\n&gt;&gt;&gt; email = next_email()\n&gt;&gt;&gt; print(f\"Using email: {email}\")\n&gt;&gt;&gt;\n&gt;&gt;&gt; # Multiple calls rotate through pool\n&gt;&gt;&gt; emails = [next_email() for _ in range(3)]\n&gt;&gt;&gt; print(f\"Rotation: {emails}\")\n</code></pre> Thread Safety <p>This function is thread-safe and can be called concurrently from multiple threads without requiring external synchronization. The underlying itertools.cycle iterator handles concurrent access safely.</p> Configuration <p>The email pool can be customized via the PMCGRAB_EMAILS environment variable. If not set, uses a default pool of test email addresses.</p> <p>Example environment setup: export PMCGRAB_EMAILS=\"user1@example.com,user2@example.com\"</p> Note <p>NCBI Entrez requires a valid email address for API identification. The email is used to identify the requester and enable NCBI to contact users about API usage if necessary. Use real email addresses in production environments.</p> Source code in <code>src/pmcgrab/infrastructure/settings.py</code> <pre><code>def next_email() -&gt; str:\n    \"\"\"Return the next email address in round-robin rotation.\n\n    Provides thread-safe access to the email pool using round-robin rotation.\n    This ensures fair distribution of API requests across available email\n    addresses, which helps with rate limiting and API usage policies.\n\n    Returns:\n        str: Next email address from the configured pool\n\n    Examples:\n        &gt;&gt;&gt; # Get email for NCBI Entrez request\n        &gt;&gt;&gt; email = next_email()\n        &gt;&gt;&gt; print(f\"Using email: {email}\")\n        &gt;&gt;&gt;\n        &gt;&gt;&gt; # Multiple calls rotate through pool\n        &gt;&gt;&gt; emails = [next_email() for _ in range(3)]\n        &gt;&gt;&gt; print(f\"Rotation: {emails}\")\n\n    Thread Safety:\n        This function is thread-safe and can be called concurrently from\n        multiple threads without requiring external synchronization. The\n        underlying itertools.cycle iterator handles concurrent access safely.\n\n    Configuration:\n        The email pool can be customized via the PMCGRAB_EMAILS environment\n        variable. If not set, uses a default pool of test email addresses.\n\n        Example environment setup:\n        export PMCGRAB_EMAILS=\"user1@example.com,user2@example.com\"\n\n    Note:\n        NCBI Entrez requires a valid email address for API identification.\n        The email is used to identify the requester and enable NCBI to\n        contact users about API usage if necessary. Use real email addresses\n        in production environments.\n    \"\"\"\n    return next(_email_cycle)\n</code></pre>"},{"location":"api/core/#example-usage","title":"Example Usage","text":"<pre><code>from pmcgrab.application.processing import process_single_pmc\nfrom pmcgrab.infrastructure.settings import next_email\n\n# Process a single PMC article\nemail = next_email()\ndata = process_single_pmc(\"7114487\")\n\nif data:\n    print(f\"Title: {data['title']}\")\n    print(f\"Authors: {len(data['authors'])}\")\n    print(f\"Sections: {list(data['body'].keys())}\")\n</code></pre>"},{"location":"api/processing/","title":"Processing API","text":"<p>Functions for processing PMC articles efficiently.</p>"},{"location":"api/processing/#primary-processing-function","title":"Primary Processing Function","text":"<p>The recommended way to process PMC articles:</p>"},{"location":"api/processing/#process_single_pmc","title":"process_single_pmc","text":"<p>options: show_source: true show_root_heading: true show_root_toc_entry: false show_object_full_path: false show_category_heading: false show_signature_annotations: true heading_level: 3</p>"},{"location":"api/processing/#pmcgrab.application.processing.process_single_pmc","title":"pmcgrab.application.processing.process_single_pmc","text":"<pre><code>process_single_pmc(\n    pmc_id: str,\n) -&gt; dict[str, str | dict | list] | None\n</code></pre> <p>Download and parse a single PMC article into normalized dictionary format.</p> <p>Application-layer function that handles the complete processing pipeline for a single PMC article: fetching XML, parsing content, extracting structured data, and normalizing for JSON serialization. Includes timeout protection and robust error handling.</p> <p>Parameters:</p> Name Type Description Default <code>str</code> <p>String representation of the PMC ID (e.g., \"7181753\")</p> required <p>Returns:</p> Type Description <code>dict[str, str | dict | list] | None</code> <p>dict[str, str | dict | list] | None: Normalized article dictionary with keys: - pmc_id: Article identifier - title: Article title - abstract: Plain text abstract - body: Dictionary of section titles mapped to text content - authors: Normalized author information - Journal and publication metadata - Content metadata (funding, ethics, etc.)</p> <code>dict[str, str | dict | list] | None</code> <p>Returns None if processing fails or article has no usable content.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; article_data = process_single_pmc(\"7181753\")\n&gt;&gt;&gt; if article_data:\n...     print(f\"Title: {article_data['title']}\")\n...     print(f\"Sections: {list(article_data['body'].keys())}\")\n...     print(f\"Authors: {len(article_data['authors'])}\")\n</code></pre> Note <p>This function includes a 60-second timeout for network/parsing operations and performs garbage collection for memory management in batch scenarios. All values are normalized using normalize_value() for JSON compatibility.</p> Source code in <code>src/pmcgrab/application/processing.py</code> <pre><code>def process_single_pmc(pmc_id: str) -&gt; dict[str, str | dict | list] | None:\n    \"\"\"Download and parse a single PMC article into normalized dictionary format.\n\n    Application-layer function that handles the complete processing pipeline\n    for a single PMC article: fetching XML, parsing content, extracting\n    structured data, and normalizing for JSON serialization. Includes\n    timeout protection and robust error handling.\n\n    Args:\n        pmc_id: String representation of the PMC ID (e.g., \"7181753\")\n\n    Returns:\n        dict[str, str | dict | list] | None: Normalized article dictionary with keys:\n            - pmc_id: Article identifier\n            - title: Article title\n            - abstract: Plain text abstract\n            - body: Dictionary of section titles mapped to text content\n            - authors: Normalized author information\n            - Journal and publication metadata\n            - Content metadata (funding, ethics, etc.)\n        Returns None if processing fails or article has no usable content.\n\n    Examples:\n        &gt;&gt;&gt; article_data = process_single_pmc(\"7181753\")\n        &gt;&gt;&gt; if article_data:\n        ...     print(f\"Title: {article_data['title']}\")\n        ...     print(f\"Sections: {list(article_data['body'].keys())}\")\n        ...     print(f\"Authors: {len(article_data['authors'])}\")\n\n    Note:\n        This function includes a 60-second timeout for network/parsing operations\n        and performs garbage collection for memory management in batch scenarios.\n        All values are normalized using normalize_value() for JSON compatibility.\n    \"\"\"\n    gc.collect()\n    paper_info: dict[str, str | dict | list] = {}\n    body_info: dict[str, str] = {}\n\n    try:\n        pmc_id_num = int(pmc_id)\n        current_email = next_email()\n\n        # Time-boxed network / parsing\n        signal.alarm(60)\n        try:\n            paper = build_paper_from_pmc(\n                pmc_id_num, email=current_email, download=True, validate=False\n            )\n        except TimeoutException:\n            return None\n        finally:\n            signal.alarm(0)\n\n        if paper is None:\n            return None\n\n        # ---------------- Text body extraction -------------------------\n        body_sections = paper.body\n        if body_sections is not None:\n            try:\n                iter(body_sections)  # Ensure iterable\n                sec_counter = 1\n                for section in body_sections:\n                    try:\n                        text = getattr(\n                            section, \"get_section_text\", lambda s=section: str(s)\n                        )()\n                        title = (\n                            section.title\n                            if getattr(section, \"title\", None)\n                            else f\"Section {sec_counter}\"\n                        )\n                        sec_counter += 1\n                        body_info[title] = text\n                    except Exception:\n                        pass  # Robustness: ignore malformed sections\n            except (TypeError, ValueError):\n                pass\n\n        # ---------------- Assemble output dict -------------------------\n        paper_info[\"pmc_id\"] = str(pmc_id_num)\n        paper_info[\"abstract\"] = paper.abstract_as_str() if paper.abstract else \"\"\n        paper_info[\"has_data\"] = str(paper.has_data)\n        paper_info[\"body\"] = body_info or {}\n        paper_info[\"title\"] = paper.title or \"\"\n        paper_info[\"authors\"] = (\n            normalize_value(paper.authors) if paper.authors is not None else \"\"\n        )\n        paper_info[\"non_author_contributors\"] = (\n            normalize_value(paper.non_author_contributors)\n            if paper.non_author_contributors is not None\n            else \"\"\n        )\n        paper_info[\"publisher_name\"] = (\n            normalize_value(paper.publisher_name)\n            if paper.publisher_name is not None\n            else \"\"\n        )\n        paper_info[\"publisher_location\"] = (\n            normalize_value(paper.publisher_location)\n            if paper.publisher_location is not None\n            else \"\"\n        )\n        paper_info[\"article_id\"] = (\n            normalize_value(paper.article_id) if paper.article_id is not None else \"\"\n        )\n        paper_info[\"journal_title\"] = (\n            normalize_value(paper.journal_title)\n            if paper.journal_title is not None\n            else \"\"\n        )\n        paper_info[\"journal_id\"] = (\n            normalize_value(paper.journal_id) if paper.journal_id is not None else \"\"\n        )\n        paper_info[\"issn\"] = (\n            normalize_value(paper.issn) if paper.issn is not None else \"\"\n        )\n        paper_info[\"article_types\"] = (\n            normalize_value(paper.article_types)\n            if paper.article_types is not None\n            else \"\"\n        )\n        paper_info[\"article_categories\"] = (\n            normalize_value(paper.article_categories)\n            if paper.article_categories is not None\n            else \"\"\n        )\n        paper_info[\"published_date\"] = (\n            normalize_value(paper.published_date)\n            if paper.published_date is not None\n            else \"\"\n        )\n        paper_info[\"volume\"] = (\n            normalize_value(paper.volume) if paper.volume is not None else \"\"\n        )\n        paper_info[\"issue\"] = (\n            normalize_value(paper.issue) if paper.issue is not None else \"\"\n        )\n        paper_info[\"permissions\"] = (\n            normalize_value(paper.permissions) if paper.permissions is not None else \"\"\n        )\n        paper_info[\"copyright\"] = (\n            normalize_value(paper.copyright) if paper.copyright is not None else \"\"\n        )\n        paper_info[\"license\"] = (\n            normalize_value(paper.license) if paper.license is not None else \"\"\n        )\n        paper_info[\"funding\"] = (\n            normalize_value(paper.funding) if paper.funding is not None else \"\"\n        )\n        paper_info[\"footnote\"] = (\n            normalize_value(paper.footnote) if paper.footnote is not None else \"\"\n        )\n        paper_info[\"acknowledgements\"] = (\n            normalize_value(paper.acknowledgements)\n            if paper.acknowledgements is not None\n            else \"\"\n        )\n        paper_info[\"notes\"] = (\n            normalize_value(paper.notes) if paper.notes is not None else \"\"\n        )\n        paper_info[\"custom_meta\"] = (\n            normalize_value(paper.custom_meta) if paper.custom_meta is not None else \"\"\n        )\n        paper_info[\"last_updated\"] = normalize_value(getattr(paper, \"last_updated\", \"\"))\n\n        # Normalise nested structures one last time\n        paper_info = {k: normalize_value(v) for k, v in paper_info.items()}\n        if not paper_info.get(\"body\"):\n            return None\n        return paper_info\n\n    finally:\n        with contextlib.suppress(Exception):\n            del body_info, paper\n        gc.collect()\n</code></pre>"},{"location":"api/processing/#pmcgrab.application.processing.process_single_pmc(pmc_id)","title":"<code>pmc_id</code>","text":""},{"location":"api/processing/#recommended-usage-pattern","title":"Recommended Usage Pattern","text":"<pre><code># \u2500\u2500\u2500 Recommended Processing Pattern \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\nimport json\nfrom pathlib import Path\n\nfrom pmcgrab.application.processing import process_single_pmc\nfrom pmcgrab.infrastructure.settings import next_email\n\n# The PMC IDs we want to process\nPMC_IDS = [\"7114487\", \"3084273\", \"7690653\", \"5707528\", \"7979870\"]\n\nOUT_DIR = Path(\"pmc_output\")\nOUT_DIR.mkdir(exist_ok=True)\n\nfor pmcid in PMC_IDS:\n    email = next_email()\n    print(f\"\u2022 Fetching PMC{pmcid} using email {email} \u2026\")\n    data = process_single_pmc(pmcid)\n    if data is None:\n        print(f\"  \u21b3 FAILED to parse PMC{pmcid}\")\n        continue\n\n    # Pretty-print a few key fields\n    print(\n        f\"  Title   : {data['title'][:80]}{'\u2026' if len(data['title']) &gt; 80 else ''}\\n\"\n        f\"  Abstract: {data['abstract'][:120]}{'\u2026' if len(data['abstract']) &gt; 120 else ''}\\n\"\n        f\"  Authors : {len(data['authors']) if data['authors'] else 0}\"\n    )\n\n    # Persist full JSON\n    dest = OUT_DIR / f\"PMC{pmcid}.json\"\n    with dest.open(\"w\", encoding=\"utf-8\") as fh:\n        json.dump(data, fh, indent=2, ensure_ascii=False)\n    print(f\"  \u21b3 JSON saved to {dest}\\n\")\n</code></pre>"},{"location":"api/processing/#email-management","title":"Email Management","text":""},{"location":"api/processing/#next_email","title":"next_email","text":"<p>options: show_source: true show_root_heading: true show_root_toc_entry: false show_object_full_path: false show_category_heading: false show_signature_annotations: true heading_level: 3</p> <p>This function automatically rotates through available email addresses for NCBI API requests, ensuring proper rate limiting and compliance.</p>"},{"location":"api/processing/#pmcgrab.infrastructure.settings.next_email","title":"pmcgrab.infrastructure.settings.next_email","text":"<pre><code>next_email() -&gt; str\n</code></pre> <p>Return the next email address in round-robin rotation.</p> <p>Provides thread-safe access to the email pool using round-robin rotation. This ensures fair distribution of API requests across available email addresses, which helps with rate limiting and API usage policies.</p> <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>Next email address from the configured pool</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; # Get email for NCBI Entrez request\n&gt;&gt;&gt; email = next_email()\n&gt;&gt;&gt; print(f\"Using email: {email}\")\n&gt;&gt;&gt;\n&gt;&gt;&gt; # Multiple calls rotate through pool\n&gt;&gt;&gt; emails = [next_email() for _ in range(3)]\n&gt;&gt;&gt; print(f\"Rotation: {emails}\")\n</code></pre> Thread Safety <p>This function is thread-safe and can be called concurrently from multiple threads without requiring external synchronization. The underlying itertools.cycle iterator handles concurrent access safely.</p> Configuration <p>The email pool can be customized via the PMCGRAB_EMAILS environment variable. If not set, uses a default pool of test email addresses.</p> <p>Example environment setup: export PMCGRAB_EMAILS=\"user1@example.com,user2@example.com\"</p> Note <p>NCBI Entrez requires a valid email address for API identification. The email is used to identify the requester and enable NCBI to contact users about API usage if necessary. Use real email addresses in production environments.</p> Source code in <code>src/pmcgrab/infrastructure/settings.py</code> <pre><code>def next_email() -&gt; str:\n    \"\"\"Return the next email address in round-robin rotation.\n\n    Provides thread-safe access to the email pool using round-robin rotation.\n    This ensures fair distribution of API requests across available email\n    addresses, which helps with rate limiting and API usage policies.\n\n    Returns:\n        str: Next email address from the configured pool\n\n    Examples:\n        &gt;&gt;&gt; # Get email for NCBI Entrez request\n        &gt;&gt;&gt; email = next_email()\n        &gt;&gt;&gt; print(f\"Using email: {email}\")\n        &gt;&gt;&gt;\n        &gt;&gt;&gt; # Multiple calls rotate through pool\n        &gt;&gt;&gt; emails = [next_email() for _ in range(3)]\n        &gt;&gt;&gt; print(f\"Rotation: {emails}\")\n\n    Thread Safety:\n        This function is thread-safe and can be called concurrently from\n        multiple threads without requiring external synchronization. The\n        underlying itertools.cycle iterator handles concurrent access safely.\n\n    Configuration:\n        The email pool can be customized via the PMCGRAB_EMAILS environment\n        variable. If not set, uses a default pool of test email addresses.\n\n        Example environment setup:\n        export PMCGRAB_EMAILS=\"user1@example.com,user2@example.com\"\n\n    Note:\n        NCBI Entrez requires a valid email address for API identification.\n        The email is used to identify the requester and enable NCBI to\n        contact users about API usage if necessary. Use real email addresses\n        in production environments.\n    \"\"\"\n    return next(_email_cycle)\n</code></pre>"},{"location":"development/architecture/","title":"Architecture","text":"<p>PMCGrab follows clean architecture principles with clear separation of concerns.</p>"},{"location":"development/architecture/#overview","title":"Overview","text":"<pre><code>graph TB\n    CLI[CLI Layer] --&gt; App[Application Layer]\n    App --&gt; Domain[Domain Layer]\n    App --&gt; Common[Common Utilities]\n    App --&gt; Infra[Infrastructure Layer]\n    Domain --&gt; Models[Domain Models]\n    Common --&gt; Utils[Utilities &amp; Helpers]\n    Infra --&gt; External[External APIs]\n</code></pre>"},{"location":"development/architecture/#layer-descriptions","title":"Layer Descriptions","text":""},{"location":"development/architecture/#cli-layer-pmcgrabcli","title":"CLI Layer (<code>pmcgrab.cli</code>)","text":"<ul> <li>Command-line interface</li> <li>Argument parsing</li> <li>User interaction</li> <li>Progress reporting</li> </ul>"},{"location":"development/architecture/#application-layer-pmcgrabapplication","title":"Application Layer (<code>pmcgrab.application</code>)","text":"<ul> <li>Use case orchestration</li> <li>Business workflow logic</li> <li>Paper construction</li> <li>Content parsing coordination</li> </ul>"},{"location":"development/architecture/#domain-layer-pmcgrabdomain","title":"Domain Layer (<code>pmcgrab.domain</code>)","text":"<ul> <li>Core business entities</li> <li>Value objects</li> <li>Domain rules</li> <li>No external dependencies</li> </ul>"},{"location":"development/architecture/#common-layer-pmcgrabcommon","title":"Common Layer (<code>pmcgrab.common</code>)","text":"<ul> <li>Shared utilities</li> <li>HTML cleaning</li> <li>XML processing</li> <li>Serialization helpers</li> </ul>"},{"location":"development/architecture/#infrastructure-layer-pmcgrabinfrastructure","title":"Infrastructure Layer (<code>pmcgrab.infrastructure</code>)","text":"<ul> <li>External API clients</li> <li>HTTP utilities</li> <li>Settings management</li> <li>I/O operations</li> </ul>"},{"location":"development/architecture/#key-components","title":"Key Components","text":""},{"location":"development/architecture/#paper-model","title":"Paper Model","text":"<p>The central domain entity representing a PMC article:</p> <pre><code>@dataclass\nclass Paper:\n    pmcid: str\n    title: str\n    authors: List[Author]\n    abstract: Dict[str, str]\n    body: Dict[str, str]\n    citations: List[Citation]\n    # ... other fields\n</code></pre>"},{"location":"development/architecture/#parser-system","title":"Parser System","text":"<p>Modular parsing system with specialized parsers:</p> <ul> <li><code>MetadataParser</code>: Article metadata</li> <li><code>ContentParser</code>: Main content sections</li> <li><code>ContributorParser</code>: Authors and affiliations</li> <li><code>SectionParser</code>: Section organization</li> </ul>"},{"location":"development/architecture/#processing-pipeline","title":"Processing Pipeline","text":"<pre><code>sequenceDiagram\n    participant User\n    participant CLI\n    participant App\n    participant Parser\n    participant Fetcher\n\n    User-&gt;&gt;CLI: pmcgrab PMC123456\n    CLI-&gt;&gt;App: process_pmc_ids()\n    App-&gt;&gt;Fetcher: get_xml()\n    Fetcher--&gt;&gt;App: XML content\n    App-&gt;&gt;Parser: parse_paper()\n    Parser--&gt;&gt;App: Paper object\n    App--&gt;&gt;CLI: Processing result\n    CLI--&gt;&gt;User: JSON output\n</code></pre>"},{"location":"development/architecture/#design-patterns","title":"Design Patterns","text":""},{"location":"development/architecture/#factory-pattern","title":"Factory Pattern","text":"<p>Used for creating Paper objects from various sources:</p> <pre><code>class PaperFactory:\n    @staticmethod\n    def from_pmc(pmcid: str) -&gt; Paper:\n        # Construction logic\n\n    @staticmethod\n    def from_xml(xml_content: str) -&gt; Paper:\n        # Construction logic\n</code></pre>"},{"location":"development/architecture/#strategy-pattern","title":"Strategy Pattern","text":"<p>Different parsing strategies for different content types:</p> <pre><code>class ContentParser:\n    def __init__(self, strategy: ParsingStrategy):\n        self.strategy = strategy\n\n    def parse(self, content: str) -&gt; Dict:\n        return self.strategy.parse(content)\n</code></pre>"},{"location":"development/architecture/#builder-pattern","title":"Builder Pattern","text":"<p>Complex Paper object construction:</p> <pre><code>class PaperBuilder:\n    def add_metadata(self, metadata: Dict) -&gt; 'PaperBuilder':\n        # Add metadata\n        return self\n\n    def add_content(self, content: Dict) -&gt; 'PaperBuilder':\n        # Add content\n        return self\n\n    def build(self) -&gt; Paper:\n        # Construct final Paper object\n</code></pre>"},{"location":"development/architecture/#data-flow","title":"Data Flow","text":""},{"location":"development/architecture/#single-paper-processing","title":"Single Paper Processing","text":"<ol> <li>Input: PMC ID from user</li> <li>Fetch: Download XML from NCBI</li> <li>Parse: Extract structured data</li> <li>Build: Construct Paper object</li> <li>Output: Serialize to JSON</li> </ol>"},{"location":"development/architecture/#batch-processing","title":"Batch Processing","text":"<ol> <li>Input: List of PMC IDs</li> <li>Chunk: Split into batches</li> <li>Parallel: Process batches concurrently</li> <li>Aggregate: Collect results</li> <li>Report: Generate summary</li> </ol>"},{"location":"development/architecture/#error-handling","title":"Error Handling","text":""},{"location":"development/architecture/#error-types","title":"Error Types","text":"<pre><code>class PMCGrabError(Exception):\n    \"\"\"Base exception for PMCGrab\"\"\"\n\nclass NetworkError(PMCGrabError):\n    \"\"\"Network-related errors\"\"\"\n\nclass ParsingError(PMCGrabError):\n    \"\"\"XML parsing errors\"\"\"\n\nclass ValidationError(PMCGrabError):\n    \"\"\"Data validation errors\"\"\"\n</code></pre>"},{"location":"development/architecture/#error-handling-strategy","title":"Error Handling Strategy","text":"<ul> <li>Fail Fast: For critical errors</li> <li>Graceful Degradation: For parsing issues</li> <li>Retry Logic: For network errors</li> <li>User Feedback: Clear error messages</li> </ul>"},{"location":"development/architecture/#testing-architecture","title":"Testing Architecture","text":""},{"location":"development/architecture/#test-structure","title":"Test Structure","text":"<pre><code>tests/\n\u251c\u2500\u2500 unit/           # Unit tests\n\u251c\u2500\u2500 integration/    # Integration tests\n\u251c\u2500\u2500 e2e/           # End-to-end tests\n\u251c\u2500\u2500 fixtures/      # Test data\n\u2514\u2500\u2500 conftest.py    # Test configuration\n</code></pre>"},{"location":"development/architecture/#test-categories","title":"Test Categories","text":"<ul> <li>Unit Tests: Individual components</li> <li>Integration Tests: Component interactions</li> <li>End-to-end Tests: Full workflows</li> <li>Performance Tests: Speed and memory usage</li> </ul>"},{"location":"development/architecture/#configuration-management","title":"Configuration Management","text":""},{"location":"development/architecture/#settings-hierarchy","title":"Settings Hierarchy","text":"<ol> <li>Command line arguments (highest priority)</li> <li>Environment variables</li> <li>Configuration files</li> <li>Default values (lowest priority)</li> </ol>"},{"location":"development/architecture/#configuration-schema","title":"Configuration Schema","text":"<pre><code>@dataclass\nclass Settings:\n    email: str\n    timeout: int = 30\n    max_retries: int = 3\n    batch_size: int = 10\n    workers: int = 4\n</code></pre>"},{"location":"development/architecture/#extension-points","title":"Extension Points","text":""},{"location":"development/architecture/#custom-parsers","title":"Custom Parsers","text":"<p>Implement the <code>ParserInterface</code>:</p> <pre><code>class CustomParser(ParserInterface):\n    def parse(self, xml_root: Element) -&gt; Dict:\n        # Custom parsing logic\n</code></pre>"},{"location":"development/architecture/#custom-output-formats","title":"Custom Output Formats","text":"<p>Implement the <code>SerializerInterface</code>:</p> <pre><code>class CustomSerializer(SerializerInterface):\n    def serialize(self, paper: Paper) -&gt; str:\n        # Custom serialization logic\n</code></pre>"},{"location":"development/architecture/#performance-considerations","title":"Performance Considerations","text":""},{"location":"development/architecture/#optimization-strategies","title":"Optimization Strategies","text":"<ol> <li>Concurrent Processing: Multiple workers</li> <li>Caching: XML and parsed data</li> <li>Memory Management: Streaming for large datasets</li> <li>Network Optimization: Connection pooling</li> </ol>"},{"location":"development/architecture/#monitoring","title":"Monitoring","text":"<ul> <li>Processing speed metrics</li> <li>Memory usage tracking</li> <li>Error rate monitoring</li> <li>Network latency measurements</li> </ul> <p>This architecture ensures PMCGrab is maintainable, testable, and extensible while providing excellent performance for both single article and batch processing scenarios.</p>"},{"location":"development/contributing/","title":"Contributing","text":"<p>We welcome contributions to PMCGrab! This guide will help you get started.</p>"},{"location":"development/contributing/#getting-started","title":"Getting Started","text":"<ol> <li>Fork the repository on GitHub</li> <li>Clone your fork locally:    <pre><code>git clone https://github.com/rajdeepmondaldotcom/pmcgrab.git\ncd pmcgrab\n</code></pre></li> <li>Set up development environment:    <pre><code>uv sync --dev\n</code></pre></li> </ol>"},{"location":"development/contributing/#development-workflow","title":"Development Workflow","text":"<ol> <li>Create a feature branch:</li> </ol> <pre><code>git checkout -b feature/your-feature-name\n</code></pre> <ol> <li> <p>Make your changes following our coding standards</p> </li> <li> <p>Run tests:</p> </li> </ol> <pre><code>uv run pytest\n</code></pre> <ol> <li>Run linting:</li> </ol> <pre><code>uv run ruff check .\nuv run ruff format .\n</code></pre> <ol> <li>Commit your changes:</li> </ol> <pre><code>git commit -m \"feat: add new feature description\"\n</code></pre> <ol> <li>Push and create a pull request</li> </ol>"},{"location":"development/contributing/#coding-standards","title":"Coding Standards","text":"<ul> <li>Follow PEP 8 style guidelines</li> <li>Use type hints for all functions</li> <li>Write comprehensive docstrings in Google style</li> <li>Add tests for new functionality</li> <li>Keep functions focused and well-named</li> </ul>"},{"location":"development/contributing/#testing","title":"Testing","text":"<ul> <li>Write unit tests for all new code</li> <li>Ensure tests pass locally before submitting</li> <li>Add integration tests for complex features</li> <li>Maintain high test coverage</li> </ul>"},{"location":"development/contributing/#documentation","title":"Documentation","text":"<ul> <li>Update documentation for new features</li> <li>Include examples in docstrings</li> <li>Update the changelog</li> </ul>"},{"location":"development/contributing/#questions","title":"Questions?","text":"<p>Open an issue on GitHub if you have questions or need help.</p>"},{"location":"development/setup/","title":"Development Setup","text":"<p>Complete guide for setting up PMCGrab for development.</p>"},{"location":"development/setup/#prerequisites","title":"Prerequisites","text":"<ul> <li>Python 3.10+</li> <li>Git</li> <li>uv (recommended)</li> </ul>"},{"location":"development/setup/#installation","title":"Installation","text":""},{"location":"development/setup/#1-clone-the-repository","title":"1. Clone the Repository","text":"<pre><code>git clone https://github.com/rajdeepmondaldotcom/pmcgrab.git\ncd pmcgrab\n</code></pre>"},{"location":"development/setup/#2-set-up-virtual-environment","title":"2. Set Up Virtual Environment","text":"<pre><code>uv sync --dev --all-groups\n</code></pre>"},{"location":"development/setup/#3-verify-installation","title":"3. Verify Installation","text":"<pre><code>uv run python -c \"import pmcgrab; print(pmcgrab.__version__)\"\nuv run pytest --version\n</code></pre>"},{"location":"development/setup/#development-tools","title":"Development Tools","text":""},{"location":"development/setup/#code-quality","title":"Code Quality","text":"<pre><code># Linting\nuv run ruff check .\n\n# Formatting\nuv run ruff format .\n\n# Type checking\nuv run mypy src/\n\n# Security scanning\nuv run bandit -r src/\n</code></pre>"},{"location":"development/setup/#testing","title":"Testing","text":"<pre><code># Run all tests\nuv run pytest\n\n# Run with coverage\nuv run pytest --cov=pmcgrab\n\n# Run specific test file\nuv run pytest tests/test_model.py\n</code></pre>"},{"location":"development/setup/#documentation","title":"Documentation","text":"<pre><code># Build documentation\nuv run mkdocs serve\n\n# View at http://localhost:8000\n</code></pre>"},{"location":"development/setup/#pre-commit-hooks","title":"Pre-commit Hooks","text":"<p>Install pre-commit hooks:</p> <pre><code>uv run pre-commit install\n</code></pre> <p>This will run checks automatically before each commit.</p>"},{"location":"development/setup/#environment-variables","title":"Environment Variables","text":"<p>For development, create a <code>.env</code> file:</p> <pre><code>PMCGRAB_EMAIL=your-dev-email@example.com\nPMCGRAB_DEBUG=true\n</code></pre>"},{"location":"development/setup/#ide-setup","title":"IDE Setup","text":""},{"location":"development/setup/#vs-code","title":"VS Code","text":"<p>Recommended extensions:</p> <ul> <li>Python</li> <li>Pylance</li> <li>Ruff</li> <li>Test Explorer UI</li> </ul> <p>Workspace settings in <code>.vscode/settings.json</code>:</p> <pre><code>{\n  \"python.defaultInterpreterPath\": \".venv/bin/python\",\n  \"python.linting.enabled\": true,\n  \"python.formatting.provider\": \"black\",\n  \"python.testing.pytestEnabled\": true\n}\n</code></pre>"},{"location":"development/setup/#pycharm","title":"PyCharm","text":"<ol> <li>Open project in PyCharm</li> <li>Configure Python interpreter to use virtual environment</li> <li>Enable pytest as test runner</li> <li>Configure Ruff as code formatter</li> </ol>"},{"location":"development/setup/#common-development-tasks","title":"Common Development Tasks","text":""},{"location":"development/setup/#adding-a-new-feature","title":"Adding a New Feature","text":"<ol> <li>Create feature branch</li> <li>Add implementation in <code>src/pmcgrab/</code></li> <li>Add tests in <code>tests/</code></li> <li>Update documentation</li> <li>Run all checks</li> <li>Submit pull request</li> </ol>"},{"location":"development/setup/#debugging","title":"Debugging","text":"<pre><code># Enable verbose logging\nexport PMCGRAB_LOG_LEVEL=DEBUG\n\n# Run with debugger\nuv run python -m pdb -c continue -m pmcgrab.cli.pmcgrab_cli --help\n</code></pre>"},{"location":"development/setup/#performance-profiling","title":"Performance Profiling","text":"<pre><code># Profile code\nuv run python -m cProfile -o profile.stats script.py\n\n# Analyze results\nuv run python -c \"import pstats; pstats.Stats('profile.stats').sort_stats('cumulative').print_stats(20)\"\n</code></pre>"},{"location":"development/setup/#troubleshooting","title":"Troubleshooting","text":""},{"location":"development/setup/#common-issues","title":"Common Issues","text":"<ol> <li>Import errors: Ensure virtual environment is activated</li> <li>Test failures: Check if all dependencies are installed</li> <li>Linting errors: Run <code>uv run ruff format .</code> to auto-fix</li> </ol>"},{"location":"development/setup/#getting-help","title":"Getting Help","text":"<ul> <li>Check existing issues on GitHub</li> <li>Ask questions in discussions</li> <li>Join our development chat (if available)</li> </ul>"},{"location":"development/testing/","title":"Testing","text":"<p>Comprehensive testing guide for PMCGrab development.</p>"},{"location":"development/testing/#test-structure","title":"Test Structure","text":"<pre><code>tests/\n\u251c\u2500\u2500 conftest.py              # Shared test configuration\n\u251c\u2500\u2500 test_model.py           # Paper model tests\n\u251c\u2500\u2500 test_parser.py          # Parser tests\n\u251c\u2500\u2500 test_cli_complete.py    # CLI integration tests\n\u251c\u2500\u2500 test_processing.py      # Processing pipeline tests\n\u2514\u2500\u2500 fixtures/               # Test data and fixtures\n    \u251c\u2500\u2500 sample_articles/\n    \u2514\u2500\u2500 mock_responses/\n</code></pre>"},{"location":"development/testing/#running-tests","title":"Running Tests","text":""},{"location":"development/testing/#basic-test-execution","title":"Basic Test Execution","text":"<pre><code># Run all tests\nuv run pytest\n\n# Run with verbose output\nuv run pytest -v\n\n# Run specific test file\nuv run pytest tests/test_model.py\n\n# Run specific test function\nuv run pytest tests/test_model.py::test_paper_creation\n</code></pre>"},{"location":"development/testing/#coverage-analysis","title":"Coverage Analysis","text":"<pre><code># Run tests with coverage\nuv run pytest --cov=pmcgrab\n\n# Generate HTML coverage report\nuv run pytest --cov=pmcgrab --cov-report=html\n\n# View coverage report\nopen htmlcov/index.html\n</code></pre>"},{"location":"development/testing/#performance-testing","title":"Performance Testing","text":"<pre><code># Run performance tests\nuv run pytest -m performance\n\n# Profile test execution\nuv run pytest --profile\n\n# Benchmark tests\nuv run pytest --benchmark-only\n</code></pre>"},{"location":"development/testing/#test-categories","title":"Test Categories","text":""},{"location":"development/testing/#unit-tests","title":"Unit Tests","text":"<p>Test individual components in isolation:</p> <pre><code>def test_paper_title_extraction():\n    \"\"\"Test paper title extraction from XML.\"\"\"\n    xml_content = \"\"\"\n    &lt;article&gt;\n        &lt;front&gt;\n            &lt;article-meta&gt;\n                &lt;title-group&gt;\n                    &lt;article-title&gt;Test Article Title&lt;/article-title&gt;\n                &lt;/title-group&gt;\n            &lt;/article-meta&gt;\n        &lt;/front&gt;\n    &lt;/article&gt;\n    \"\"\"\n\n    paper = Paper.from_xml(xml_content, email=\"test@example.com\")\n    assert paper.title == \"Test Article Title\"\n</code></pre>"},{"location":"development/testing/#integration-tests","title":"Integration Tests","text":"<p>Test component interactions:</p> <pre><code>def test_full_paper_processing():\n    \"\"\"Test complete paper processing pipeline.\"\"\"\n    pmcid = \"7181753\"\n\n    with patch('pmcgrab.fetch.get_xml') as mock_get_xml:\n        mock_get_xml.return_value = load_fixture('sample_article.xml')\n\n        paper = Paper.from_pmc(pmcid, email=\"test@example.com\")\n\n        assert paper.pmcid == f\"PMC{pmcid}\"\n        assert paper.title is not None\n        assert len(paper.authors) &gt; 0\n</code></pre>"},{"location":"development/testing/#end-to-end-tests","title":"End-to-End Tests","text":"<p>Test complete workflows:</p> <pre><code>def test_cli_batch_processing(tmp_path):\n    \"\"\"Test CLI batch processing functionality.\"\"\"\n    # Create test input file\n    input_file = tmp_path / \"test_ids.txt\"\n    input_file.write_text(\"7181753\\n3539614\\n\")\n\n    # Run CLI command\n    result = run_cli([\n        \"--input-file\", str(input_file),\n        \"--output-dir\", str(tmp_path),\n        \"--email\", \"test@example.com\"\n    ])\n\n    assert result.exit_code == 0\n    assert (tmp_path / \"PMC7181753.json\").exists()\n    assert (tmp_path / \"PMC3539614.json\").exists()\n</code></pre>"},{"location":"development/testing/#test-fixtures","title":"Test Fixtures","text":""},{"location":"development/testing/#creating-test-data","title":"Creating Test Data","text":"<pre><code># conftest.py\n@pytest.fixture\ndef sample_paper_xml():\n    \"\"\"Sample PMC article XML for testing.\"\"\"\n    return \"\"\"\n    &lt;article&gt;\n        &lt;front&gt;\n            &lt;article-meta&gt;\n                &lt;article-id pub-id-type=\"pmcid\"&gt;PMC7181753&lt;/article-id&gt;\n                &lt;title-group&gt;\n                    &lt;article-title&gt;Sample Article&lt;/article-title&gt;\n                &lt;/title-group&gt;\n            &lt;/article-meta&gt;\n        &lt;/front&gt;\n        &lt;body&gt;\n            &lt;sec sec-type=\"intro\"&gt;\n                &lt;title&gt;Introduction&lt;/title&gt;\n                &lt;p&gt;Sample introduction text.&lt;/p&gt;\n            &lt;/sec&gt;\n        &lt;/body&gt;\n    &lt;/article&gt;\n    \"\"\"\n\n@pytest.fixture\ndef mock_paper():\n    \"\"\"Mock Paper object for testing.\"\"\"\n    return Paper(\n        pmcid=\"PMC7181753\",\n        title=\"Test Article\",\n        authors=[],\n        abstract={},\n        body={\"Introduction\": \"Test content\"},\n        citations=[],\n        tables=[],\n        figures=[]\n    )\n</code></pre>"},{"location":"development/testing/#external-service-mocking","title":"External Service Mocking","text":"<pre><code>@pytest.fixture\ndef mock_ncbi_response():\n    \"\"\"Mock NCBI API response.\"\"\"\n    with patch('requests.get') as mock_get:\n        mock_response = Mock()\n        mock_response.status_code = 200\n        mock_response.content = load_fixture('sample_article.xml')\n        mock_get.return_value = mock_response\n        yield mock_get\n\ndef test_article_fetching(mock_ncbi_response):\n    \"\"\"Test article fetching with mocked NCBI response.\"\"\"\n    xml_content = get_xml(\"7181753\", email=\"test@example.com\")\n    assert xml_content is not None\n    mock_ncbi_response.assert_called_once()\n</code></pre>"},{"location":"development/testing/#testing-best-practices","title":"Testing Best Practices","text":""},{"location":"development/testing/#test-organization","title":"Test Organization","text":"<pre><code>class TestPaperModel:\n    \"\"\"Test cases for Paper model.\"\"\"\n\n    def test_paper_creation(self):\n        \"\"\"Test basic paper creation.\"\"\"\n        pass\n\n    def test_paper_serialization(self):\n        \"\"\"Test paper to JSON serialization.\"\"\"\n        pass\n\n    def test_paper_validation(self):\n        \"\"\"Test paper data validation.\"\"\"\n        pass\n\nclass TestPaperParsing:\n    \"\"\"Test cases for paper parsing.\"\"\"\n\n    def test_metadata_parsing(self):\n        \"\"\"Test metadata extraction.\"\"\"\n        pass\n\n    def test_content_parsing(self):\n        \"\"\"Test content extraction.\"\"\"\n        pass\n</code></pre>"},{"location":"development/testing/#parameterized-tests","title":"Parameterized Tests","text":"<pre><code>@pytest.mark.parametrize(\"pmcid,expected_title\", [\n    (\"7181753\", \"COVID-19 Research Article\"),\n    (\"3539614\", \"Machine Learning Study\"),\n    (\"5454911\", \"Clinical Trial Results\")\n])\ndef test_multiple_articles(pmcid, expected_title):\n    \"\"\"Test processing multiple articles.\"\"\"\n    with patch('pmcgrab.fetch.get_xml') as mock_get_xml:\n        mock_get_xml.return_value = create_mock_xml(expected_title)\n\n        paper = Paper.from_pmc(pmcid, email=\"test@example.com\")\n        assert paper.title == expected_title\n</code></pre>"},{"location":"development/testing/#error-testing","title":"Error Testing","text":"<pre><code>def test_invalid_pmcid():\n    \"\"\"Test handling of invalid PMC IDs.\"\"\"\n    with pytest.raises(ValueError, match=\"Invalid PMC ID\"):\n        Paper.from_pmc(\"invalid_id\", email=\"test@example.com\")\n\ndef test_network_error():\n    \"\"\"Test handling of network errors.\"\"\"\n    with patch('requests.get', side_effect=requests.ConnectionError):\n        with pytest.raises(NetworkError):\n            get_xml(\"7181753\", email=\"test@example.com\")\n</code></pre>"},{"location":"development/testing/#async-testing","title":"Async Testing","text":"<pre><code>@pytest.mark.asyncio\nasync def test_async_processing():\n    \"\"\"Test asynchronous processing.\"\"\"\n    processor = AsyncProcessor(email=\"test@example.com\")\n\n    with patch.object(processor, 'process_single') as mock_process:\n        mock_process.return_value = mock_paper()\n\n        results = await processor.process_batch([\"7181753\", \"3539614\"])\n        assert len(results) == 2\n</code></pre>"},{"location":"development/testing/#mock-strategies","title":"Mock Strategies","text":""},{"location":"development/testing/#http-mocking-with-responses","title":"HTTP Mocking with Responses","text":"<pre><code>import responses\n\n@responses.activate\ndef test_api_integration():\n    \"\"\"Test API integration with responses library.\"\"\"\n    responses.add(\n        responses.GET,\n        \"https://eutils.ncbi.nlm.nih.gov/entrez/eutils/efetch.fcgi\",\n        body=load_fixture('sample_article.xml'),\n        status=200,\n        content_type='application/xml'\n    )\n\n    xml_content = get_xml(\"7181753\", email=\"test@example.com\")\n    assert xml_content is not None\n</code></pre>"},{"location":"development/testing/#database-mocking","title":"Database Mocking","text":"<pre><code>@pytest.fixture\ndef mock_database():\n    \"\"\"Mock database for testing.\"\"\"\n    with patch('pmcgrab.storage.DatabaseConnection') as mock_db:\n        mock_db.return_value.execute.return_value = []\n        yield mock_db\n\ndef test_database_operations(mock_database):\n    \"\"\"Test database operations.\"\"\"\n    storage = PaperStorage()\n    storage.save_paper(mock_paper())\n\n    mock_database.return_value.execute.assert_called_once()\n</code></pre>"},{"location":"development/testing/#continuous-integration","title":"Continuous Integration","text":""},{"location":"development/testing/#github-actions-configuration","title":"GitHub Actions Configuration","text":"<pre><code># .github/workflows/test.yml\nname: Tests\n\non: [push, pull_request]\n\njobs:\n  test:\n    runs-on: ubuntu-latest\n    strategy:\n      matrix:\n        python-version: [3.10, 3.11, 3.12]\n\n    steps:\n      - uses: actions/checkout@v4\n      - name: Set up Python\n        uses: actions/setup-python@v5\n        with:\n          python-version: ${{ matrix.python-version }}\n\n      - name: Install uv\n        run: curl -LsSf https://astral.sh/uv/install.sh | sh\n\n      - name: Install dependencies\n        run: uv sync --dev --all-groups\n\n      - name: Run tests\n        run: uv run pytest --cov=pmcgrab\n\n      - name: Upload coverage\n        uses: codecov/codecov-action@v3\n</code></pre>"},{"location":"development/testing/#test-markers","title":"Test Markers","text":"<pre><code># Mark slow tests\n@pytest.mark.slow\ndef test_large_batch_processing():\n    \"\"\"Test processing large batches (slow).\"\"\"\n    pass\n\n# Mark integration tests\n@pytest.mark.integration\ndef test_full_workflow():\n    \"\"\"Test complete workflow (integration).\"\"\"\n    pass\n\n# Mark performance tests\n@pytest.mark.performance\ndef test_processing_speed():\n    \"\"\"Test processing performance.\"\"\"\n    pass\n</code></pre> <p>Run specific test categories:</p> <pre><code># Skip slow tests\nuv run pytest -m \"not slow\"\n\n# Run only integration tests\nuv run pytest -m integration\n\n# Run performance tests\nuv run pytest -m performance\n</code></pre>"},{"location":"development/testing/#debugging-tests","title":"Debugging Tests","text":""},{"location":"development/testing/#running-tests-in-debug-mode","title":"Running Tests in Debug Mode","text":"<pre><code># Run with debugging\nuv run pytest --pdb\n\n# Run with debugging on first failure\nuv run pytest --pdb -x\n\n# Run with verbose output\nuv run pytest -v -s\n</code></pre>"},{"location":"development/testing/#test-debugging-tips","title":"Test Debugging Tips","text":"<ol> <li>Use print statements for quick debugging</li> <li>Set breakpoints with <code>pytest --pdb</code></li> <li>Isolate failing tests with specific test selection</li> <li>Check test logs for detailed error information</li> <li>Use mock.assert_called_with() to verify interactions</li> </ol>"},{"location":"development/testing/#performance-testing_1","title":"Performance Testing","text":""},{"location":"development/testing/#benchmarking","title":"Benchmarking","text":"<pre><code>import time\nimport pytest\n\ndef test_parsing_performance():\n    \"\"\"Benchmark paper parsing performance.\"\"\"\n    xml_content = load_large_fixture('large_article.xml')\n\n    start_time = time.time()\n    paper = Paper.from_xml(xml_content, email=\"test@example.com\")\n    end_time = time.time()\n\n    processing_time = end_time - start_time\n    assert processing_time &lt; 5.0  # Should complete within 5 seconds\n    assert paper is not None\n</code></pre>"},{"location":"development/testing/#memory-testing","title":"Memory Testing","text":"<pre><code>import psutil\nimport os\n\ndef test_memory_usage():\n    \"\"\"Test memory usage during processing.\"\"\"\n    process = psutil.Process(os.getpid())\n    initial_memory = process.memory_info().rss\n\n    # Process large batch\n    results = process_large_batch(large_pmc_ids)\n\n    final_memory = process.memory_info().rss\n    memory_increase = final_memory - initial_memory\n\n    # Memory increase should be reasonable\n    assert memory_increase &lt; 500 * 1024 * 1024  # Less than 500MB\n</code></pre> <p>This comprehensive testing framework ensures PMCGrab maintains high quality and reliability across all components and use cases.</p>"},{"location":"examples/advanced-usage/","title":"Advanced Usage","text":"<p>Advanced patterns and techniques for power users of PMCGrab.</p>"},{"location":"examples/advanced-usage/#custom-processing-functions","title":"Custom Processing Functions","text":""},{"location":"examples/advanced-usage/#processing-with-custom-logic","title":"Processing with Custom Logic","text":"<pre><code>import json\nfrom pathlib import Path\nfrom pmcgrab.application.processing import process_single_pmc\nfrom pmcgrab.infrastructure.settings import next_email\n\ndef process_with_filtering(pmcids, output_dir=\"filtered_output\"):\n    \"\"\"Process PMCs with custom filtering logic.\"\"\"\n\n    output_path = Path(output_dir)\n    output_path.mkdir(exist_ok=True)\n\n    results = []\n\n    for pmcid in pmcids:\n        email = next_email()\n        print(f\"Processing PMC{pmcid}...\")\n\n        data = process_single_pmc(pmcid)\n        if data is None:\n            continue\n\n        # Custom filtering - only keep papers with abstracts &gt; 500 chars\n        if len(data.get('abstract', '')) &lt; 500:\n            print(f\"  Skipping PMC{pmcid} - abstract too short\")\n            continue\n\n        # Save filtered result\n        output_file = output_path / f\"PMC{pmcid}.json\"\n        with output_file.open('w', encoding='utf-8') as f:\n            json.dump(data, f, indent=2, ensure_ascii=False)\n\n        results.append(data)\n        print(f\"  Saved PMC{pmcid} ({len(data['abstract'])} char abstract)\")\n\n    return results\n\n# Usage\npmcids = [\"7114487\", \"3084273\", \"7690653\"]\nfiltered_papers = process_with_filtering(pmcids)\nprint(f\"Processed {len(filtered_papers)} papers that met criteria\")\n</code></pre>"},{"location":"examples/advanced-usage/#data-analysis-integration","title":"Data Analysis Integration","text":""},{"location":"examples/advanced-usage/#converting-to-dataframe","title":"Converting to DataFrame","text":"<pre><code>import pandas as pd\nfrom pmcgrab.application.processing import process_single_pmc\n\ndef create_papers_dataframe(pmcids):\n    \"\"\"Create a pandas DataFrame from processed papers.\"\"\"\n\n    papers_data = []\n\n    for pmcid in pmcids:\n        data = process_single_pmc(pmcid)\n        if data is None:\n            continue\n\n        # Extract key fields for analysis\n        paper_info = {\n            'pmcid': pmcid,\n            'title': data.get('title', ''),\n            'journal': data.get('journal', ''),\n            'pub_date': data.get('pub_date', ''),\n            'author_count': len(data.get('authors', [])),\n            'abstract_length': len(data.get('abstract', '')),\n            'section_count': len(data.get('body', {})),\n            'has_figures': len(data.get('figures', [])) &gt; 0,\n            'has_tables': len(data.get('tables', [])) &gt; 0\n        }\n        papers_data.append(paper_info)\n\n    return pd.DataFrame(papers_data)\n\n# Usage\npmcids = [\"7114487\", \"3084273\", \"7690653\", \"5707528\"]\ndf = create_papers_dataframe(pmcids)\n\nprint(\"Dataset Overview:\")\nprint(df.describe())\nprint(f\"\\nJournals: {df['journal'].unique()}\")\n</code></pre>"},{"location":"examples/advanced-usage/#error-handling-and-retry-logic","title":"Error Handling and Retry Logic","text":""},{"location":"examples/advanced-usage/#robust-processing-with-retries","title":"Robust Processing with Retries","text":"<pre><code>import time\nimport json\nfrom pathlib import Path\nfrom pmcgrab.application.processing import process_single_pmc\nfrom pmcgrab.infrastructure.settings import next_email\n\ndef robust_processing(pmcids, max_retries=3, delay=2):\n    \"\"\"Process PMCs with robust error handling and retries.\"\"\"\n\n    output_dir = Path(\"robust_output\")\n    output_dir.mkdir(exist_ok=True)\n\n    successful = []\n    failed = []\n\n    for pmcid in pmcids:\n        success = False\n\n        for attempt in range(max_retries):\n            try:\n                email = next_email()\n                print(f\"Processing PMC{pmcid} (attempt {attempt + 1}/{max_retries})\")\n\n                data = process_single_pmc(pmcid)\n\n                if data is not None:\n                    # Save successful result\n                    output_file = output_dir / f\"PMC{pmcid}.json\"\n                    with output_file.open('w', encoding='utf-8') as f:\n                        json.dump(data, f, indent=2, ensure_ascii=False)\n\n                    successful.append(pmcid)\n                    print(f\"  Success Successfully processed PMC{pmcid}\")\n                    success = True\n                    break\n                else:\n                    print(f\"  \u26a0 No data returned for PMC{pmcid}\")\n\n            except Exception as e:\n                print(f\"  Error Error processing PMC{pmcid}: {str(e)}\")\n                if attempt &lt; max_retries - 1:\n                    print(f\"    Retrying in {delay} seconds...\")\n                    time.sleep(delay)\n\n        if not success:\n            failed.append(pmcid)\n            print(f\"  Error Failed to process PMC{pmcid} after {max_retries} attempts\")\n\n    print(f\"\\nResults: {len(successful)} successful, {len(failed)} failed\")\n    return successful, failed\n\n# Usage\npmcids = [\"7114487\", \"3084273\", \"7690653\", \"5707528\", \"7979870\"]\nsuccessful, failed = robust_processing(pmcids)\n\nif failed:\n    print(f\"Failed PMC IDs: {failed}\")\n</code></pre>"},{"location":"examples/advanced-usage/#configuration-and-settings","title":"Configuration and Settings","text":""},{"location":"examples/advanced-usage/#custom-email-rotation","title":"Custom Email Rotation","text":"<pre><code>from pmcgrab.infrastructure.settings import next_email\n\n# PMCGrab automatically rotates through available emails\n# You can also check the current email configuration:\n\ndef show_email_status():\n    \"\"\"Display current email configuration status.\"\"\"\n    for i in range(5):  # Show first 5 emails in rotation\n        email = next_email()\n        print(f\"Email {i+1}: {email}\")\n\nshow_email_status()\n</code></pre>"},{"location":"examples/advanced-usage/#performance-optimization","title":"Performance Optimization","text":""},{"location":"examples/advanced-usage/#memory-efficient-processing","title":"Memory-Efficient Processing","text":"<pre><code>def memory_efficient_processing(pmcids, batch_size=5):\n    \"\"\"Process large datasets with memory efficiency.\"\"\"\n\n    total_batches = len(pmcids) // batch_size + (1 if len(pmcids) % batch_size else 0)\n\n    for batch_num in range(total_batches):\n        start_idx = batch_num * batch_size\n        end_idx = min(start_idx + batch_size, len(pmcids))\n        batch = pmcids[start_idx:end_idx]\n\n        print(f\"Processing batch {batch_num + 1}/{total_batches}\")\n\n        for pmcid in batch:\n            data = process_single_pmc(pmcid)\n            if data:\n                # Process immediately and don't store in memory\n                output_file = Path(f\"batch_output/PMC{pmcid}.json\")\n                output_file.parent.mkdir(exist_ok=True)\n\n                with output_file.open('w', encoding='utf-8') as f:\n                    json.dump(data, f, indent=2, ensure_ascii=False)\n\n                print(f\"  Saved PMC{pmcid}\")\n                # Clear data from memory\n                del data\n\n# Usage for large datasets\nlarge_pmcid_list = [str(i) for i in range(7000000, 7000100)]  # Example: 100 PMC IDs\nmemory_efficient_processing(large_pmcid_list, batch_size=10)\n</code></pre> <p>These advanced patterns provide robust, scalable solutions for research workflows while maintaining memory efficiency and error resilience.</p>"},{"location":"examples/cli-examples/","title":"CLI Examples","text":"<p>Practical command-line examples for common PMCGrab usage scenarios.</p>"},{"location":"examples/cli-examples/#basic-usage","title":"Basic Usage","text":""},{"location":"examples/cli-examples/#single-article-processing","title":"Single Article Processing","text":"<pre><code># Basic usage - process one article\nuv run python -m pmcgrab PMC7181753\n\n# With email specification (recommended)\nuv run uv run python -m pmcgrab --email researcher@university.edu PMC7181753\n\n# Save to custom directory\nuv run uv run python -m pmcgrab --output-dir ./papers --email researcher@university.edu PMC7181753\n</code></pre>"},{"location":"examples/cli-examples/#multiple-articles","title":"Multiple Articles","text":"<pre><code># Process several articles at once\nuv run uv run python -m pmcgrab PMC7181753 PMC3539614 PMC5454911\n\n# With parallel processing\nuv run uv run python -m pmcgrab --workers 4 PMC7181753 PMC3539614 PMC5454911\n</code></pre>"},{"location":"examples/cli-examples/#file-input","title":"File Input","text":""},{"location":"examples/cli-examples/#from-text-file","title":"From Text File","text":"<p>Create <code>pmcids.txt</code>:</p> <pre><code>7181753\n3539614\n5454911\n7979870\n</code></pre> <p>Process the list:</p> <pre><code>uv run python -m pmcgrab --input-file pmcids.txt --email researcher@university.edu\n</code></pre>"},{"location":"examples/cli-examples/#advanced-options","title":"Advanced Options","text":""},{"location":"examples/cli-examples/#batch-processing-with-configuration","title":"Batch Processing with Configuration","text":"<pre><code># Process with custom settings\nuv run python -m pmcgrab \\\n    --input-file pmcids.txt \\\n    --output-dir ./output \\\n    --email researcher@university.edu \\\n    --workers 4 \\\n    --batch-size 10 \\\n    --max-retries 2 \\\n    --verbose\n</code></pre>"},{"location":"examples/cli-examples/#common-parameters","title":"Common Parameters","text":"Parameter Description Example <code>--email</code> Your email for NCBI requests <code>--email user@example.com</code> <code>--output-dir</code> Output directory for JSON files <code>--output-dir ./papers</code> <code>--workers</code> Number of parallel workers <code>--workers 4</code> <code>--batch-size</code> Articles per batch <code>--batch-size 10</code> <code>--max-retries</code> Retry failed requests <code>--max-retries 2</code> <code>--verbose</code> Detailed output <code>--verbose</code> <code>--input-file</code> Read PMC IDs from file <code>--input-file list.txt</code>"},{"location":"examples/cli-examples/#output","title":"Output","text":"<p>PMCGrab saves each article as a JSON file:</p> <pre><code>output/\n\u251c\u2500\u2500 PMC7181753.json\n\u251c\u2500\u2500 PMC3539614.json\n\u2514\u2500\u2500 PMC5454911.json\n</code></pre> <p>Each JSON file contains structured article data including title, abstract, body sections, authors, and metadata.</p>"},{"location":"examples/python-examples/","title":"Python Examples","text":"<p>Real-world examples showing how to use PMCGrab effectively.</p>"},{"location":"examples/python-examples/#interactive-jupyter-tutorial","title":"Interactive Jupyter Tutorial","text":"<p>For a complete hands-on experience, check out our interactive Jupyter notebook:</p> <p>PMCGrab Tutorial Notebook</p> <p>You can also download it directly: pmcgrab_tutorial.ipynb</p> <p>This notebook covers:</p> <ul> <li>Installation and setup (including uv)</li> <li>Single paper processing</li> <li>Batch processing with multiple papers</li> <li>Data analysis and visualization</li> <li>RAG chunk preparation</li> <li>Export formats for different use cases</li> </ul>"},{"location":"examples/python-examples/#code-examples","title":"Code Examples","text":""},{"location":"examples/python-examples/#batch-processing-multiple-papers","title":"Batch Processing Multiple Papers","text":"<p>This example demonstrates how to process multiple PMC articles and save them as JSON files:</p> <pre><code># \u2500\u2500\u2500 examples/run_three_pmcs.py \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\nimport json\nfrom pathlib import Path\n\nfrom pmcgrab.application.processing import process_single_pmc\nfrom pmcgrab.infrastructure.settings import next_email\n\n# The PMC IDs we want to process\nPMC_IDS = [\"7114487\", \"3084273\", \"7690653\", \"5707528\", \"7979870\"]\n\nOUT_DIR = Path(\"pmc_output\")\nOUT_DIR.mkdir(exist_ok=True)\n\nfor pmcid in PMC_IDS:\n    email = next_email()\n    print(f\"\u2022 Fetching PMC{pmcid} using email {email} \u2026\")\n    data = process_single_pmc(pmcid)\n    if data is None:\n        print(f\"  \u21b3 FAILED to parse PMC{pmcid}\")\n        continue\n\n    # Pretty-print a few key fields\n    print(\n        f\"  Title   : {data['title'][:80]}{'\u2026' if len(data['title']) &gt; 80 else ''}\\n\"\n        f\"  Abstract: {data['abstract'][:120]}{'\u2026' if len(data['abstract']) &gt; 120 else ''}\\n\"\n        f\"  Authors : {len(data['authors']) if data['authors'] else 0}\"\n    )\n\n    # Persist full JSON\n    dest = OUT_DIR / f\"PMC{pmcid}.json\"\n    with dest.open(\"w\", encoding=\"utf-8\") as fh:\n        json.dump(data, fh, indent=2, ensure_ascii=False)\n    print(f\"  \u21b3 JSON saved to {dest}\\n\")\n</code></pre>"},{"location":"examples/python-examples/#key-features-demonstrated","title":"Key Features Demonstrated","text":"<ul> <li>Batch Processing: Efficiently processes multiple PMC articles</li> <li>Error Handling: Gracefully handles failed parsing attempts</li> <li>Pretty Output: Shows key information during processing</li> <li>JSON Export: Saves complete article data as structured JSON files</li> <li>Email Rotation: Uses the built-in email rotation system</li> </ul>"},{"location":"examples/python-examples/#expected-output","title":"Expected Output","text":"<pre><code>\u2022 Fetching PMC7114487 using email researcher1@example.com \u2026\n  Title   : COVID-19 pandemic response and lessons learned from the\u2026\n  Abstract: The COVID-19 pandemic has posed unprecedented challenges to global health\u2026\n  Authors : 5\n  \u21b3 JSON saved to pmc_output/PMC7114487.json\n\n\u2022 Fetching PMC3084273 using email researcher2@example.com \u2026\n  Title   : Machine learning approaches in genomics and personalized medicine\u2026\n  Abstract: Recent advances in machine learning have revolutionized the field of\u2026\n  Authors : 3\n  \u21b3 JSON saved to pmc_output/PMC3084273.json\n</code></pre> <p>This example is perfect for:</p> <ul> <li>Building literature review datasets</li> <li>Creating training data for AI models</li> <li>Systematic research paper analysis</li> <li>Academic research workflows</li> </ul>"},{"location":"getting-started/complete-beginner-guide/","title":"Complete Beginner Guide: From Zero to AI-Ready Scientific Literature","text":"<p>Never used Python package managers or processed scientific literature before? This guide starts from absolute zero and gets you processing PMC articles in 10 minutes.</p>"},{"location":"getting-started/complete-beginner-guide/#what-youll-accomplish","title":"What You'll Accomplish","text":"<p>By the end of this guide, you'll:</p> <ol> <li>Have <code>uv</code> and <code>pmcgrab</code> installed and working</li> <li>Download and parse your first scientific paper from PMC</li> <li>Understand the JSON structure that's perfect for AI/ML workflows</li> <li>Run a complete example that processes multiple papers</li> <li>Know how to use this data for RAG, vector databases, or LLM training</li> </ol>"},{"location":"getting-started/complete-beginner-guide/#prerequisites","title":"Prerequisites","text":"<ul> <li>Python 3.10+ installed on your system</li> <li>Internet connection (to download papers from PMC)</li> <li>Terminal/Command Prompt access</li> </ul> <p>Check your Python version</p> <p><code>bash     python --version     # or on some systems:     python3 --version</code></p>"},{"location":"getting-started/complete-beginner-guide/#step-1-install-uv-the-fast-package-manager","title":"Step 1: Install uv (The Fast Package Manager)","text":"<p><code>uv</code> is a blazing-fast Python package manager that makes installing and managing packages much easier than traditional <code>pip</code>.</p>"},{"location":"getting-started/complete-beginner-guide/#install-uv","title":"Install uv:","text":"macOS/Linux <p><code>bash     curl -LsSf https://astral.sh/uv/install.sh | sh</code></p> Windows <p><code>powershell     powershell -ExecutionPolicy ByPass -c \"irm https://astral.sh/uv/install.ps1 | iex\"</code></p> Already have pip? <p><code>bash     pip install uv</code></p>"},{"location":"getting-started/complete-beginner-guide/#verify-installation","title":"Verify installation:","text":"<pre><code># Restart your terminal first, then:\nuv --version\n</code></pre> <p>You should see something like <code>uv 0.4.x</code> or similar.</p>"},{"location":"getting-started/complete-beginner-guide/#step-2-install-pmcgrab","title":"Step 2: Install PMCGrab","text":"<p>Now install PMCGrab using uv:</p> <pre><code>uv add pmcgrab\n</code></pre> <p>First time using uv?</p> <p>If this is your first time using <code>uv add</code>, it might ask to create a virtual environment. Say yes! This keeps your project dependencies clean.</p>"},{"location":"getting-started/complete-beginner-guide/#verify-pmcgrab-installation","title":"Verify PMCGrab installation:","text":"<pre><code># Create a file called test_install.py and run it\nimport pmcgrab\nprint(\"PMCGrab version:\", pmcgrab.__version__)\nprint(\"Installation successful!\")\n</code></pre> <pre><code>uv run python test_install.py\n</code></pre>"},{"location":"getting-started/complete-beginner-guide/#step-3-your-first-paper-understanding-pmc-ids","title":"Step 3: Your First Paper - Understanding PMC IDs","text":"<p>PMC IDs are unique identifiers for papers in PubMed Central. For example:</p> <ul> <li>URL: <code>https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7114487/</code></li> <li>PMC ID: <code>7114487</code> (just the number part)</li> </ul> <p>Let's fetch this paper and see what PMCGrab gives us:</p> <pre><code># Create first_paper.py\nfrom pmcgrab.application.processing import process_single_pmc\n\n# Process a single paper (this might take 5-10 seconds)\npmcid = \"7114487\"\nprint(f\"Fetching PMC{pmcid} from PubMed Central...\")\n\ndata = process_single_pmc(pmcid)\n\nif data:\n    print(\"Success! Here's what we got:\")\n    print(f\"Title: {data['title']}\")\n    print(f\"Journal: {data['journal']}\")\n    print(f\"Number of authors: {len(data['authors'])}\")\n    print(f\"Paper has these sections: {list(data['body'].keys())}\")\n    print(f\"Abstract preview: {data['abstract'][:200]}...\")\nelse:\n    print(\"Failed to fetch the paper\")\n</code></pre> <p>Run it:</p> <pre><code>uv run python first_paper.py\n</code></pre>"},{"location":"getting-started/complete-beginner-guide/#step-4-understanding-the-json-structure-aiml-gold","title":"Step 4: Understanding the JSON Structure (AI/ML Gold!)","text":"<p>The output from PMCGrab is structured JSON that's perfect for AI workflows. Let's explore it:</p> <pre><code># Create explore_structure.py\nimport json\nfrom pmcgrab.application.processing import process_single_pmc\n\n# Get the data\ndata = process_single_pmc(\"7114487\")\n\n# Save to a file so we can examine it\nwith open(\"sample_paper.json\", \"w\", encoding=\"utf-8\") as f:\n    json.dump(data, f, indent=2, ensure_ascii=False)\n\nprint(\"Paper saved to sample_paper.json\")\nprint(\"\\nLet's explore the structure:\")\n\n# Top-level structure\nprint(f\"Top-level keys: {list(data.keys())}\")\n\n# Authors structure\nprint(f\"\\nFirst author: {data['authors'][0]}\")\n\n# Body sections (perfect for RAG!)\nprint(f\"\\nAvailable sections:\")\nfor section, content in data['body'].items():\n    print(f\"  - {section}: {len(content)} characters\")\n    print(f\"    Preview: {content[:100]}...\\n\")\n</code></pre> <p>Run it:</p> <pre><code>uv run python explore_structure.py\n</code></pre>"},{"location":"getting-started/complete-beginner-guide/#step-5-batch-processing-the-real-power","title":"Step 5: Batch Processing - The Real Power","text":"<p>Now let's process multiple papers at once. This is where PMCGrab shines for building datasets:</p> <pre><code># Create batch_example.py\nimport json\nfrom pathlib import Path\nfrom pmcgrab.application.processing import process_single_pmc\n\n# Papers related to COVID-19 and machine learning in medicine\nINTERESTING_PAPERS = {\n    \"7114487\": \"COVID-19 pandemic response\",\n    \"3084273\": \"Machine learning in genomics\",\n    \"7181753\": \"Single-cell skin transcriptomics\",\n    \"5707528\": \"Deep learning applications\",\n    \"7979870\": \"Bioinformatics methods\"\n}\n\n# Create output directory\noutput_dir = Path(\"processed_papers\")\noutput_dir.mkdir(exist_ok=True)\n\nprint(\"Starting batch processing...\")\nprint(f\"Results will be saved to: {output_dir}\")\nprint(\"=\" * 50)\n\nsuccessful = 0\nfailed = 0\n\nfor pmcid, description in INTERESTING_PAPERS.items():\n    print(f\"\\nProcessing PMC{pmcid}: {description}\")\n\n    try:\n        data = process_single_pmc(pmcid)\n\n        if data:\n            # Save as JSON\n            output_file = output_dir / f\"PMC{pmcid}.json\"\n            with open(output_file, \"w\", encoding=\"utf-8\") as f:\n                json.dump(data, f, indent=2, ensure_ascii=False)\n\n            print(f\"   Success! Title: {data['title'][:60]}...\")\n            print(f\"   {len(data['authors'])} authors, {len(data['body'])} sections\")\n            print(f\"   Saved to: {output_file}\")\n            successful += 1\n        else:\n            print(f\"   Failed to process PMC{pmcid}\")\n            failed += 1\n\n    except Exception as e:\n        print(f\"   Error processing PMC{pmcid}: {e}\")\n        failed += 1\n\nprint(\"\\n\" + \"=\" * 50)\nprint(f\"Batch processing complete!\")\nprint(f\"Successful: {successful}\")\nprint(f\"Failed: {failed}\")\nprint(f\"Check the '{output_dir}' folder for your JSON files\")\n</code></pre> <p>Run it:</p> <pre><code>uv run python batch_example.py\n</code></pre>"},{"location":"getting-started/complete-beginner-guide/#step-6-what-can-you-do-with-this-data","title":"Step 6: What Can You Do With This Data?","text":"<p>The JSON files you now have are perfect for AI workflows:</p>"},{"location":"getting-started/complete-beginner-guide/#rag-retrieval-augmented-generation","title":"RAG (Retrieval-Augmented Generation)","text":"<pre><code># Example: Extract content for vector database\nsections_for_rag = []\nfor section, content in data['body'].items():\n    sections_for_rag.append({\n        \"source\": f\"PMC{data['pmc_id']}\",\n        \"section\": section,\n        \"content\": content,\n        \"metadata\": {\n            \"title\": data['title'],\n            \"journal\": data['journal'],\n            \"authors\": [f\"{a['First_Name']} {a['Last_Name']}\" for a in data['authors']]\n        }\n    })\n</code></pre>"},{"location":"getting-started/complete-beginner-guide/#llm-training-data","title":"LLM Training Data","text":"<pre><code># Create training examples\ntraining_examples = []\nfor pmcid, paper_data in all_papers.items():\n    training_examples.append({\n        \"input\": f\"Summarize this {paper_data['journal']} paper about {paper_data['title']}\",\n        \"output\": paper_data['abstract']\n    })\n</code></pre>"},{"location":"getting-started/complete-beginner-guide/#research-analysis","title":"Research Analysis","text":"<pre><code># Analyze paper characteristics\nimport pandas as pd\n\npaper_stats = []\nfor file in Path(\"processed_papers\").glob(\"*.json\"):\n    with open(file) as f:\n        paper = json.load(f)\n\n    paper_stats.append({\n        \"pmcid\": paper['pmc_id'],\n        \"title\": paper['title'],\n        \"journal\": paper['journal'],\n        \"num_authors\": len(paper['authors']),\n        \"num_sections\": len(paper['body']),\n        \"abstract_length\": len(paper['abstract']),\n        \"total_content\": sum(len(content) for content in paper['body'].values())\n    })\n\ndf = pd.DataFrame(paper_stats)\nprint(df.describe())\n</code></pre>"},{"location":"getting-started/complete-beginner-guide/#step-7-command-line-power-user","title":"Step 7: Command Line Power User","text":"<p>PMCGrab also works from the command line for quick processing:</p> <pre><code># Process single paper\nuv run python -m pmcgrab --pmcids 7114487\n\n# Process multiple papers with 4 workers (parallel processing)\nuv run python -m pmcgrab --pmcids 7114487 3084273 7181753 --workers 4\n\n# Custom output directory\nuv run python -m pmcgrab --pmcids 7114487 --output-dir ./my_papers\n</code></pre>"},{"location":"getting-started/complete-beginner-guide/#next-steps-level-up-your-usage","title":"Next Steps: Level Up Your Usage","text":"<p>Now that you've got the basics down:</p> <ol> <li>Advanced Usage Guide - Error handling, custom processing</li> <li>Jupyter Notebook Tutorial - Interactive exploration</li> <li>CLI Reference - Complete command-line options</li> <li>API Documentation - Full API reference</li> </ol>"},{"location":"getting-started/complete-beginner-guide/#troubleshooting","title":"Troubleshooting","text":""},{"location":"getting-started/complete-beginner-guide/#common-issues","title":"Common Issues:","text":"<p>\"Failed to process PMC...\"</p> <ul> <li>The paper might not be open access</li> <li>Network connectivity issues</li> <li>Invalid PMC ID</li> </ul> <p>\"Import Error\"</p> <ul> <li>Make sure you're using <code>uv run python</code> instead of just <code>python</code></li> <li>Verify installation: <code>uv run python -c \"import pmcgrab; print('OK')\"</code></li> </ul> <p>\"No sections found\"</p> <ul> <li>Some papers have non-standard structures</li> <li>Check if the paper is a research article (not editorial, letter, etc.)</li> </ul>"},{"location":"getting-started/complete-beginner-guide/#getting-help","title":"Getting Help:","text":"<ul> <li>Full Documentation</li> <li>\ud83d\udc1b Report Issues</li> <li>\ud83d\udcac Discussions</li> </ul>"},{"location":"getting-started/complete-beginner-guide/#congratulations","title":"Congratulations!","text":"<p>You now know how to:</p> <ul> <li>Install and use PMCGrab</li> <li>Process scientific papers into AI-ready JSON</li> <li>Handle batch processing for building datasets</li> <li>Structure data for RAG, LLMs, and research analysis</li> </ul> <p>Start building amazing AI applications with scientific literature!</p>"},{"location":"getting-started/configuration/","title":"Configuration","text":"<p>PMCGrab provides simple configuration options optimized for the <code>process_single_pmc</code> workflow.</p>"},{"location":"getting-started/configuration/#email-management","title":"Email Management","text":"<p>PMCGrab automatically manages email rotation for NCBI API compliance:</p> <pre><code>from pmcgrab.infrastructure.settings import next_email\n\n# Get the next email in rotation\nemail = next_email()\nprint(f\"Using email: {email}\")\n</code></pre> <p>The system automatically rotates through available email addresses to ensure proper rate limiting and compliance with NCBI guidelines.</p>"},{"location":"getting-started/configuration/#basic-usage-pattern","title":"Basic Usage Pattern","text":"<p>The recommended configuration-free approach:</p> <pre><code>from pmcgrab.application.processing import process_single_pmc\nfrom pmcgrab.infrastructure.settings import next_email\n\n# Process a single article\nemail = next_email()  # Automatic email rotation\ndata = process_single_pmc(\"7114487\")\n\nif data:\n    print(f\"Successfully processed: {data['title']}\")\nelse:\n    print(\"Processing failed\")\n</code></pre>"},{"location":"getting-started/configuration/#batch-processing-configuration","title":"Batch Processing Configuration","text":"<p>For processing multiple articles, use the standard pattern:</p> <pre><code># \u2500\u2500\u2500 Recommended Batch Processing Pattern \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\nimport json\nfrom pathlib import Path\n\nfrom pmcgrab.application.processing import process_single_pmc\nfrom pmcgrab.infrastructure.settings import next_email\n\n# The PMC IDs we want to process\nPMC_IDS = [\"7114487\", \"3084273\", \"7690653\", \"5707528\", \"7979870\"]\n\nOUT_DIR = Path(\"pmc_output\")\nOUT_DIR.mkdir(exist_ok=True)\n\nfor pmcid in PMC_IDS:\n    email = next_email()\n    print(f\"\u2022 Fetching PMC{pmcid} using email {email} \u2026\")\n    data = process_single_pmc(pmcid)\n    if data is None:\n        print(f\"  \u21b3 FAILED to parse PMC{pmcid}\")\n        continue\n\n    # Pretty-print a few key fields\n    print(\n        f\"  Title   : {data['title'][:80]}{'\u2026' if len(data['title']) &gt; 80 else ''}\\n\"\n        f\"  Abstract: {data['abstract'][:120]}{'\u2026' if len(data['abstract']) &gt; 120 else ''}\\n\"\n        f\"  Authors : {len(data['authors']) if data['authors'] else 0}\"\n    )\n\n    # Persist full JSON\n    dest = OUT_DIR / f\"PMC{pmcid}.json\"\n    with dest.open(\"w\", encoding=\"utf-8\") as fh:\n        json.dump(data, fh, indent=2, ensure_ascii=False)\n    print(f\"  \u21b3 JSON saved to {dest}\\n\")\n</code></pre>"},{"location":"getting-started/configuration/#error-handling-configuration","title":"Error Handling Configuration","text":"<p>Built-in error handling with graceful degradation:</p> <pre><code>from pmcgrab.application.processing import process_single_pmc\nfrom pmcgrab.infrastructure.settings import next_email\n\ndef robust_processing(pmcids):\n    \"\"\"Process PMC IDs with robust error handling.\"\"\"\n    successful = []\n    failed = []\n\n    for pmcid in pmcids:\n        email = next_email()\n\n        try:\n            data = process_single_pmc(pmcid)\n            if data is not None:\n                successful.append((pmcid, data))\n                print(f\"Success PMC{pmcid}: {data['title'][:50]}...\")\n            else:\n                failed.append(pmcid)\n                print(f\"Error PMC{pmcid}: No data returned\")\n        except Exception as e:\n            failed.append(pmcid)\n            print(f\"Error PMC{pmcid}: {str(e)}\")\n\n    return successful, failed\n\n# Usage\npmcids = [\"7114487\", \"3084273\", \"invalid_id\", \"7690653\"]\nsuccessful, failed = robust_processing(pmcids)\nprint(f\"Processed: {len(successful)}, Failed: {len(failed)}\")\n</code></pre>"},{"location":"getting-started/configuration/#performance-configuration","title":"Performance Configuration","text":""},{"location":"getting-started/configuration/#memory-efficient-processing","title":"Memory-Efficient Processing","text":"<p>For large datasets, process in chunks to manage memory:</p> <pre><code>import json\nimport gc\nfrom pathlib import Path\nfrom pmcgrab.application.processing import process_single_pmc\nfrom pmcgrab.infrastructure.settings import next_email\n\ndef memory_efficient_processing(pmcids, output_dir=\"results\", batch_size=10):\n    \"\"\"Process large datasets with memory management.\"\"\"\n    output_path = Path(output_dir)\n    output_path.mkdir(exist_ok=True)\n\n    for i in range(0, len(pmcids), batch_size):\n        batch = pmcids[i:i + batch_size]\n        print(f\"Processing batch {i//batch_size + 1}: {len(batch)} articles\")\n\n        for pmcid in batch:\n            email = next_email()\n            data = process_single_pmc(pmcid)\n\n            if data is not None:\n                output_file = output_path / f\"PMC{pmcid}.json\"\n                with output_file.open('w', encoding='utf-8') as f:\n                    json.dump(data, f, indent=2, ensure_ascii=False)\n                print(f\"  Saved PMC{pmcid}\")\n                del data  # Clear from memory\n            else:\n                print(f\"  Failed PMC{pmcid}\")\n\n        # Force garbage collection after each batch\n        gc.collect()\n\n# Usage for large datasets\nlarge_pmcid_list = [str(i) for i in range(7000000, 7000100)]\nmemory_efficient_processing(large_pmcid_list, batch_size=20)\n</code></pre>"},{"location":"getting-started/configuration/#progress-tracking-configuration","title":"Progress Tracking Configuration","text":"<p>Add progress tracking for long-running processes:</p> <pre><code>from tqdm import tqdm\nfrom pmcgrab.application.processing import process_single_pmc\nfrom pmcgrab.infrastructure.settings import next_email\n\ndef process_with_progress(pmcids, output_dir=\"results\"):\n    \"\"\"Process with progress tracking.\"\"\"\n    successful = 0\n\n    for pmcid in tqdm(pmcids, desc=\"Processing papers\"):\n        email = next_email()\n        data = process_single_pmc(pmcid)\n\n        if data is not None:\n            # Save and count success\n            output_file = Path(output_dir) / f\"PMC{pmcid}.json\"\n            output_file.parent.mkdir(exist_ok=True)\n\n            with output_file.open('w', encoding='utf-8') as f:\n                json.dump(data, f, indent=2, ensure_ascii=False)\n\n            successful += 1\n            tqdm.write(f\"Success {data['title'][:40]}...\")\n        else:\n            tqdm.write(f\"Error PMC{pmcid}: Failed\")\n\n    print(f\"Completed: {successful}/{len(pmcids)} papers\")\n\n# Usage\npmcids = [\"7114487\", \"3084273\", \"7690653\", \"5707528\"]\nprocess_with_progress(pmcids)\n</code></pre>"},{"location":"getting-started/configuration/#output-configuration","title":"Output Configuration","text":""},{"location":"getting-started/configuration/#custom-output-directories","title":"Custom Output Directories","text":"<p>Organize output with custom directory structures:</p> <pre><code>from datetime import datetime\nfrom pathlib import Path\n\n# Create timestamped directories\ntimestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\noutput_dir = Path(f\"pmc_batch_{timestamp}\")\n\n# Or organize by topic\ntopic_dir = Path(\"cancer_research_papers\")\ntopic_dir.mkdir(exist_ok=True)\n</code></pre>"},{"location":"getting-started/configuration/#json-formatting-options","title":"JSON Formatting Options","text":"<p>Control JSON output formatting:</p> <pre><code>import json\nfrom pmcgrab.application.processing import process_single_pmc\n\ndata = process_single_pmc(\"7114487\")\n\nif data:\n    # Compact JSON (smaller files)\n    with open(\"compact.json\", \"w\") as f:\n        json.dump(data, f, separators=(',', ':'), ensure_ascii=False)\n\n    # Pretty JSON (human readable)\n    with open(\"pretty.json\", \"w\") as f:\n        json.dump(data, f, indent=2, ensure_ascii=False)\n\n    # With Unicode preservation\n    with open(\"unicode.json\", \"w\", encoding='utf-8') as f:\n        json.dump(data, f, indent=2, ensure_ascii=False)\n</code></pre>"},{"location":"getting-started/configuration/#command-line-configuration","title":"Command Line Configuration","text":"<p>For command-line usage, PMCGrab provides several configuration options:</p> <pre><code># Basic usage\nuv run python -m pmcgrab PMC7114487\n\n# With custom settings\nuv run python -m pmcgrab \\\n    --output-dir ./results \\\n    --workers 4 \\\n    --batch-size 10 \\\n    --email researcher@university.edu \\\n    PMC7114487 PMC3084273\n\n# From file\nuv run python -m pmcgrab --input-file pmcids.txt --output-dir results/\n</code></pre>"},{"location":"getting-started/configuration/#best-practices","title":"Best Practices","text":""},{"location":"getting-started/configuration/#production-configuration","title":"Production Configuration","text":"<pre><code>import logging\nfrom datetime import datetime\nfrom pathlib import Path\nfrom pmcgrab.application.processing import process_single_pmc\nfrom pmcgrab.infrastructure.settings import next_email\n\ndef production_processing(pmcids, base_output_dir=\"production\"):\n    \"\"\"Production-ready processing with logging and organization.\"\"\"\n\n    # Set up logging\n    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n    log_file = f\"pmcgrab_{timestamp}.log\"\n\n    logging.basicConfig(\n        level=logging.INFO,\n        format='%(asctime)s - %(levelname)s - %(message)s',\n        handlers=[\n            logging.FileHandler(log_file),\n            logging.StreamHandler()\n        ]\n    )\n\n    logger = logging.getLogger(__name__)\n    logger.info(f\"Starting processing of {len(pmcids)} articles\")\n\n    # Create organized output structure\n    output_dir = Path(base_output_dir) / f\"batch_{timestamp}\"\n    output_dir.mkdir(parents=True, exist_ok=True)\n\n    stats = {'successful': 0, 'failed': 0, 'failed_ids': []}\n\n    for pmcid in pmcids:\n        email = next_email()\n        logger.info(f\"Processing PMC{pmcid}\")\n\n        data = process_single_pmc(pmcid)\n        if data is not None:\n            output_file = output_dir / f\"PMC{pmcid}.json\"\n            with output_file.open('w', encoding='utf-8') as f:\n                json.dump(data, f, indent=2, ensure_ascii=False)\n\n            stats['successful'] += 1\n            logger.info(f\"Success: {data['title'][:50]}...\")\n        else:\n            stats['failed'] += 1\n            stats['failed_ids'].append(pmcid)\n            logger.warning(f\"Failed: PMC{pmcid}\")\n\n    # Save summary\n    summary_file = output_dir / \"summary.json\"\n    with summary_file.open('w', encoding='utf-8') as f:\n        json.dump(stats, f, indent=2)\n\n    logger.info(f\"Processing complete: {stats['successful']}/{len(pmcids)} successful\")\n    return stats\n\n# Usage\npmcids = [\"7114487\", \"3084273\", \"7690653\"]\nresults = production_processing(pmcids)\n</code></pre> <p>This configuration approach provides robust, scalable processing while maintaining simplicity and reliability.</p>"},{"location":"getting-started/installation/","title":"Installation","text":"<p>PMCGrab supports Python 3.10+. Installation relies on uv\u2014the 10-100\u00d7 faster drop-in replacement for pip. Install uv first, then add PMCGrab.</p>"},{"location":"getting-started/installation/#step-1-install-uv","title":"Step 1: Install uv","text":"<p>First, install uv (the fast Python package manager):</p>"},{"location":"getting-started/installation/#on-macos-and-linux","title":"On macOS and Linux:","text":"<pre><code>curl -LsSf https://astral.sh/uv/install.sh | sh\n</code></pre>"},{"location":"getting-started/installation/#on-windows","title":"On Windows:","text":"<pre><code>powershell -ExecutionPolicy ByPass -c \"irm https://astral.sh/uv/install.ps1 | iex\"\n</code></pre>"},{"location":"getting-started/installation/#alternative-using-pip","title":"Alternative: Using pip","text":"<pre><code>pip install uv\n</code></pre> <p>Restart your terminal after installation and verify uv is working:</p> <pre><code>uv --version\n</code></pre>"},{"location":"getting-started/installation/#step-2-install-pmcgrab","title":"Step 2: Install PMCGrab","text":""},{"location":"getting-started/installation/#option-a-using-uv-recommended","title":"Option A \u2013 Using uv (Recommended)","text":"<p>Now install PMCGrab with uv (faster resolver):</p> <pre><code>uv add pmcgrab\n</code></pre>"},{"location":"getting-started/installation/#option-b-using-pip","title":"Option B \u2013 Using pip","text":"<p>If you prefer the standard toolchain:</p> <pre><code># From PyPI (once the wheel is published)\npip install pmcgrab\n\n# Or directly from GitHub main branch\npip install \"pmcgrab @ git+https://github.com/rajdeepmondaldotcom/pmcgrab.git\"\n\n# Local checkout\npip install .\n</code></pre> <p>pip will build the wheel on the fly using the PEP 517 backend (Hatchling).</p> <p>For adding to an existing project:</p> <pre><code>uv add pmcgrab\n</code></pre> <p>For standalone installation:</p> <pre><code>uv pip install pmcgrab\n</code></pre> <p>This installs the latest stable version from PyPI along with all required dependencies.</p>"},{"location":"getting-started/installation/#from-source","title":"From Source","text":"<p>If you want the latest development version or need to modify PMCGrab:</p> <pre><code>git clone https://github.com/rajdeepmondaldotcom/pmcgrab.git\ncd pmcgrab\nuv pip install -e .\n</code></pre>"},{"location":"getting-started/installation/#development-installation","title":"Development Installation","text":"<p>For development work, install with development dependencies:</p> <pre><code>git clone https://github.com/rajdeepmondaldotcom/pmcgrab.git\ncd pmcgrab\n\n# Install with all development dependencies\nuv sync --dev --all-groups\n</code></pre>"},{"location":"getting-started/installation/#verify-installation","title":"Verify Installation","text":"<p>Test your installation:</p> <pre><code>import pmcgrab\nprint(pmcgrab.__version__)\n</code></pre> <p>Or use the command line:</p> <pre><code>uv run python -m pmcgrab --help\n</code></pre>"},{"location":"getting-started/installation/#dependencies","title":"Dependencies","text":"<p>PMCGrab requires the following packages:</p> <ul> <li>beautifulsoup4 (\u22654.13.4) - HTML parsing</li> <li>biopython (\u22651.83) - Biological data structures</li> <li>lxml (\u22654.9.0) - XML processing</li> <li>numpy (\u22651.24.0) - Numerical operations</li> <li>pandas (\u22652.0.0) - Data manipulation</li> <li>requests (\u22652.28.0) - HTTP requests</li> <li>tqdm (\u22654.64.0) - Progress bars</li> </ul>"},{"location":"getting-started/installation/#optional-dependencies","title":"Optional Dependencies","text":"<p>For development and documentation:</p> <pre><code>uv add \"pmcgrab[dev]\"    # Development tools\nuv add \"pmcgrab[docs]\"   # Documentation tools\nuv add \"pmcgrab[test]\"   # Testing dependencies\n</code></pre>"},{"location":"getting-started/installation/#system-requirements","title":"System Requirements","text":"<ul> <li>Python: 3.10, 3.11, 3.12, or 3.13</li> <li>Operating System: Windows, macOS, or Linux</li> <li>Memory: Minimum 512MB RAM (2GB+ recommended for batch processing)</li> <li>Network: Internet connection required for PMC article retrieval</li> </ul>"},{"location":"getting-started/installation/#common-issues","title":"Common Issues","text":""},{"location":"getting-started/installation/#importerror-with-lxml","title":"ImportError with lxml","text":"<p>If you encounter issues with lxml installation:</p> <pre><code># On Ubuntu/Debian\nsudo apt-get install libxml2-dev libxslt-dev python3-dev\n\n# On macOS\nbrew install libxml2 libxslt\n\n# Then reinstall\nuv pip install --force-reinstall lxml\n</code></pre>"},{"location":"getting-started/installation/#permission-errors","title":"Permission Errors","text":"<p>If you get permission errors during installation:</p> <pre><code>uv pip install --user pmcgrab\n</code></pre>"},{"location":"getting-started/installation/#virtual-environment-recommended","title":"Virtual Environment (Recommended)","text":"<p>uv automatically manages virtual environments, but you can create one explicitly:</p> <pre><code>uv venv pmcgrab-env\nsource pmcgrab-env/bin/activate  # On Windows: pmcgrab-env\\Scripts\\activate\nuv pip install pmcgrab\n</code></pre>"},{"location":"getting-started/installation/#next-steps","title":"Next Steps","text":"<p>Once installed, proceed to Quick Start to begin using PMCGrab.</p>"},{"location":"getting-started/jupyter-tutorial/","title":"Interactive Jupyter Notebook Tutorial","text":"<p>Want hands-on experience with PMCGrab? Our interactive Jupyter notebook provides a complete walkthrough from installation to building AI-ready datasets.</p>"},{"location":"getting-started/jupyter-tutorial/#whats-inside","title":"What's Inside","text":"<p>The notebook covers:</p> <ul> <li>Single Paper Processing: Start with one paper and explore the output</li> <li>Batch Processing: Build a multi-paper dataset</li> <li>AI/ML Preparation: Structure data for RAG, vector databases, and LLM training</li> <li>Data Export: Save everything in organized formats</li> <li>Analysis: Visualize and understand your dataset</li> </ul>"},{"location":"getting-started/jupyter-tutorial/#quick-start","title":"Quick Start","text":"<ol> <li>Download the notebook:</li> <li>View on GitHub (renders properly)</li> <li> <p>Direct download (local file)</p> </li> <li> <p>Install dependencies:</p> </li> </ol> <pre><code># Install uv first (if you haven't already)\ncurl -LsSf https://astral.sh/uv/install.sh | sh\n\n# Install PMCGrab and Jupyter\nuv add pmcgrab jupyter pandas matplotlib seaborn\n</code></pre> <ol> <li>Launch Jupyter:</li> </ol> <pre><code>uv run jupyter notebook\n</code></pre> <ol> <li>Open the notebook and start processing papers!</li> </ol>"},{"location":"getting-started/jupyter-tutorial/#prerequisites","title":"Prerequisites","text":"<ul> <li>Python 3.10+</li> <li>Internet connection (to fetch papers from PMC)</li> <li>Basic Python knowledge (helpful but not required)</li> </ul>"},{"location":"getting-started/jupyter-tutorial/#what-youll-build","title":"What You'll Build","text":"<p>By the end of the notebook, you'll have:</p> <ul> <li>Individual Paper JSONs: Clean, structured data for each paper</li> <li>RAG Chunks: Ready for vector database ingestion</li> <li>Training Examples: Structured for LLM fine-tuning</li> <li>Dataset Analysis: Statistical overview of your collection</li> </ul>"},{"location":"getting-started/jupyter-tutorial/#perfect-for","title":"Perfect For","text":"<ul> <li>First-time users wanting interactive exploration</li> <li>Data scientists building biomedical datasets</li> <li>AI researchers preparing training data</li> <li>Students learning about scientific text processing</li> </ul>"},{"location":"getting-started/jupyter-tutorial/#troubleshooting","title":"Troubleshooting","text":""},{"location":"getting-started/jupyter-tutorial/#common-issues","title":"Common Issues:","text":"<p>\"Failed to process PMC...\"</p> <ul> <li>Network connectivity issue</li> <li>Paper may not be open access</li> <li>Try a different PMC ID</li> </ul> <p>\"ModuleNotFoundError\"</p> <ul> <li>Make sure you're using <code>uv run jupyter notebook</code></li> <li>Verify installation: <code>uv run python -c \"import pmcgrab; print('OK')\"</code></li> </ul> <p>Notebook won't start</p> <ul> <li>Check Python version: <code>python --version</code> (need 3.10+)</li> <li>Try: <code>uv run pip install jupyter</code> then <code>uv run jupyter notebook</code></li> </ul>"},{"location":"getting-started/jupyter-tutorial/#advanced-usage","title":"Advanced Usage","text":"<p>Once you're comfortable with the basics:</p> <ul> <li>Scale up: Process 100s or 1000s of papers using the CLI</li> <li>Integrate: Connect to your vector database or ML pipeline</li> <li>Customize: Modify the notebook for your specific use case</li> </ul>"},{"location":"getting-started/jupyter-tutorial/#next-steps","title":"Next Steps","text":"<p>After completing the notebook:</p> <ul> <li>Complete Beginner Guide: More detailed explanations</li> <li>CLI Reference: Command-line usage</li> <li>Advanced Examples: Production workflows</li> </ul>"},{"location":"getting-started/jupyter-tutorial/#need-help","title":"Need Help?","text":"<ul> <li>Full Documentation</li> <li>Report Issues</li> <li>GitHub Discussions</li> </ul> <p>Ready to turn scientific literature into AI-ready data?</p> <ul> <li>View notebook on GitHub (fully rendered)</li> <li>Download notebook and start exploring!</li> </ul>"},{"location":"getting-started/quick-start/","title":"Quick Start","text":"<p>This guide will get you up and running with PMCGrab in minutes.</p>"},{"location":"getting-started/quick-start/#before-you-begin","title":"Before You Begin","text":"<p>You'll need:</p> <ol> <li>Internet connection: To fetch articles from PMC</li> <li>Valid PMC ID: Get one from PMC database</li> </ol> <p>Finding PMC IDs</p> <p>PMC IDs are numerical identifiers like <code>7181753</code>. You can find them in PMC URLs: <code>https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7181753/</code></p>"},{"location":"getting-started/quick-start/#basic-usage","title":"Basic Usage","text":"<p>Start with the simplest approach - process a single article:</p> <pre><code>from pmcgrab.application.processing import process_single_pmc\n\n# Get structured data from any PMC article\ndata = process_single_pmc(\"7114487\")\n\nif data:\n    print(f\"Title: {data['title']}\")\n    print(f\"Journal: {data['journal']}\")\n    print(f\"Authors: {len(data['authors'])}\")\n    print(f\"Sections: {list(data['body'].keys())}\")\n</code></pre>"},{"location":"getting-started/quick-start/#complete-example-process-multiple-articles","title":"Complete Example - Process Multiple Articles","text":"<p>Here's a complete working example that processes multiple papers:</p> <pre><code># \u2500\u2500\u2500 examples/run_three_pmcs.py \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\nimport json\nfrom pathlib import Path\n\nfrom pmcgrab.application.processing import process_single_pmc\nfrom pmcgrab.infrastructure.settings import next_email\n\n# The PMC IDs we want to process\nPMC_IDS = [\"7114487\", \"3084273\", \"7690653\", \"5707528\", \"7979870\"]\n\nOUT_DIR = Path(\"pmc_output\")\nOUT_DIR.mkdir(exist_ok=True)\n\nfor pmcid in PMC_IDS:\n    email = next_email()\n    print(f\"\u2022 Fetching PMC{pmcid} using email {email} \u2026\")\n    data = process_single_pmc(pmcid)\n    if data is None:\n        print(f\"  \u21b3 FAILED to parse PMC{pmcid}\")\n        continue\n\n    # Pretty-print a few key fields\n    print(\n        f\"  Title   : {data['title'][:80]}{'\u2026' if len(data['title']) &gt; 80 else ''}\\n\"\n        f\"  Abstract: {data['abstract'][:120]}{'\u2026' if len(data['abstract']) &gt; 120 else ''}\\n\"\n        f\"  Authors : {len(data['authors']) if data['authors'] else 0}\"\n    )\n\n    # Persist full JSON\n    dest = OUT_DIR / f\"PMC{pmcid}.json\"\n    with dest.open(\"w\", encoding=\"utf-8\") as fh:\n        json.dump(data, fh, indent=2, ensure_ascii=False)\n    print(f\"  \u21b3 JSON saved to {dest}\\n\")\n</code></pre> <p>Run this example:</p> <pre><code>python examples/run_three_pmcs.py\n</code></pre>"},{"location":"getting-started/quick-start/#understanding-the-output","title":"Understanding the Output","text":"<p>Each processed article returns a structured dictionary with:</p> <pre><code># Access the data\nprint(data['pmc_id'])        # PMC ID\nprint(data['title'])         # Article title\nprint(data['journal'])       # Journal information\n\n# Authors information\nfor author in data['authors'][:3]:  # First 3 authors\n    print(f\"{author['First_Name']} {author['Last_Name']}\")\n\n# Abstract content\nprint(f\"Abstract: {data['abstract'][:200]}...\")\n\n# Main content sections\nif 'Introduction' in data['body']:\n    print(f\"Introduction: {data['body']['Introduction'][:200]}...\")\nif 'Methods' in data['body']:\n    print(f\"Methods: {data['body']['Methods'][:200]}...\")\n</code></pre>"},{"location":"getting-started/quick-start/#output-structure","title":"Output Structure","text":"<p>After processing, you'll have JSON files like:</p> <pre><code>pmc_output/\n\u251c\u2500\u2500 PMC7114487.json\n\u251c\u2500\u2500 3084273.json\n\u251c\u2500\u2500 7690653.json\n\u251c\u2500\u2500 PMC5707528.json\n\u2514\u2500\u2500 PMC7979870.json\n</code></pre> <p>Each JSON file contains structured data:</p> <pre><code>{\n  \"pmc_id\": \"7114487\",\n  \"title\": \"Article title\",\n  \"abstract\": \"Article abstract\",\n  \"body\": {\n    \"Introduction\": \"Section content...\",\n    \"Methods\": \"Section content...\",\n    \"Results\": \"Section content...\",\n    \"Discussion\": \"Section content...\"\n  },\n  \"authors\": [...],\n  \"journal\": \"Journal Name\",\n  \"figures\": [...],\n  \"tables\": [...]\n}\n</code></pre>"},{"location":"getting-started/quick-start/#command-line-usage","title":"Command Line Usage","text":"<p>PMCGrab also works from the command line:</p> <pre><code># Single paper\nuv run python -m pmcgrab --pmcids 7114487\n\n# Multiple papers\nuv run python -m pmcgrab --pmcids 7114487 3084273 7690653\n\n# With custom settings\nuv run python -m pmcgrab \\\n    --output-dir ./results \\\n    --workers 4 \\\n    --pmcids 7114487 \\\n</code></pre>"},{"location":"getting-started/quick-start/#error-handling","title":"Error Handling","text":"<p>Handle processing errors gracefully:</p> <pre><code>from pmcgrab.application.processing import process_single_pmc\n\npmcid = \"7114487\"\ndata = process_single_pmc(pmcid)\n\nif data is None:\n    print(f\"Failed to process PMC{pmcid}\")\nelse:\n    print(f\"Successfully processed: {data['title']}\")\n</code></pre>"},{"location":"getting-started/quick-start/#whats-next","title":"What's Next?","text":"<p>Now that you've got the basics, choose your learning path:</p>"},{"location":"getting-started/quick-start/#new-to-pmcgrab","title":"New to PMCGrab?","text":"<ul> <li>Complete Beginner Guide: Start from absolute zero with step-by-step instructions</li> <li>Interactive Jupyter Tutorial: Hands-on notebook experience with real data</li> </ul>"},{"location":"getting-started/quick-start/#learn-more-features","title":"Learn More Features","text":"<ul> <li>Basic Usage: Learn about all available features</li> <li>Batch Processing: Advanced batch processing techniques</li> <li>CLI Reference: Command-line usage guide</li> </ul>"},{"location":"getting-started/quick-start/#see-examples","title":"See Examples","text":"<ul> <li>Python Examples: Code snippets and real-world usage</li> <li>Advanced Usage: Production-ready workflows</li> </ul>"},{"location":"getting-started/quick-start/#need-help","title":"Need Help?","text":"<ul> <li>Check the User Guide for detailed explanations</li> <li>Browse Examples for common use cases</li> <li>Open an issue on GitHub if you find bugs</li> </ul>"},{"location":"includes/mkdocs/","title":"Mkdocs","text":"<p>_[PMC]: PubMed Central _[PMCID]: PubMed Central Identifier _[NCBI]: National Center for Biotechnology Information _[XML]: eXtensible Markup Language _[JSON]: JavaScript Object Notation _[API]: Application Programming Interface _[CLI]: Command Line Interface _[RAG]: Retrieval-Augmented Generation _[LLM]: Large Language Model _[DTD]: Document Type Definition _[HTML]: HyperText Markup Language _[CSV]: Comma-Separated Values _[HTTP]: HyperText Transfer Protocol _[HTTPS]: HyperText Transfer Protocol Secure _[URL]: Uniform Resource Locator _[URI]: Uniform Resource Identifier</p>"},{"location":"user-guide/basic-usage/","title":"Basic Usage","text":"<p>PMCGrab transforms PubMed Central articles into clean, structured JSON optimized for AI pipelines and research workflows.</p>"},{"location":"user-guide/basic-usage/#core-function","title":"Core Function","text":"<p>The primary way to process articles is with <code>process_single_pmc</code>:</p> <pre><code>from pmcgrab.application.processing import process_single_pmc\n\n# Process a single PMC article\ndata = process_single_pmc(\"7114487\")\n\nif data:\n    print(f\"Title: {data['title']}\")\n    print(f\"Authors: {len(data['authors'])}\")\n    print(f\"Sections: {list(data['body'].keys())}\")\n</code></pre>"},{"location":"user-guide/basic-usage/#complete-working-example","title":"Complete Working Example","text":"<p>Here's the recommended approach for processing multiple articles:</p> <pre><code># \u2500\u2500\u2500 examples/run_three_pmcs.py \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\nimport json\nfrom pathlib import Path\n\nfrom pmcgrab.application.processing import process_single_pmc\nfrom pmcgrab.infrastructure.settings import next_email\n\n# The PMC IDs we want to process\nPMC_IDS = [\"7114487\", \"3084273\", \"7690653\", \"5707528\", \"7979870\"]\n\nOUT_DIR = Path(\"pmc_output\")\nOUT_DIR.mkdir(exist_ok=True)\n\nfor pmcid in PMC_IDS:\n    email = next_email()\n    print(f\"\u2022 Fetching PMC{pmcid} using email {email} \u2026\")\n    data = process_single_pmc(pmcid)\n    if data is None:\n        print(f\"  \u21b3 FAILED to parse PMC{pmcid}\")\n        continue\n\n    # Pretty-print a few key fields\n    print(\n        f\"  Title   : {data['title'][:80]}{'\u2026' if len(data['title']) &gt; 80 else ''}\\n\"\n        f\"  Abstract: {data['abstract'][:120]}{'\u2026' if len(data['abstract']) &gt; 120 else ''}\\n\"\n        f\"  Authors : {len(data['authors']) if data['authors'] else 0}\"\n    )\n\n    # Persist full JSON\n    dest = OUT_DIR / f\"PMC{pmcid}.json\"\n    with dest.open(\"w\", encoding=\"utf-8\") as fh:\n        json.dump(data, fh, indent=2, ensure_ascii=False)\n    print(f\"  \u21b3 JSON saved to {dest}\\n\")\n</code></pre>"},{"location":"user-guide/basic-usage/#key-features","title":"Key Features","text":""},{"location":"user-guide/basic-usage/#automatic-email-rotation","title":"Automatic Email Rotation","text":"<p>PMCGrab automatically rotates through available email addresses for NCBI API requests:</p> <pre><code>from pmcgrab.infrastructure.settings import next_email\n\n# Each call returns the next email in rotation\nemail = next_email()\nprint(f\"Using email: {email}\")\n</code></pre>"},{"location":"user-guide/basic-usage/#robust-error-handling","title":"Robust Error Handling","text":"<p>Processing returns <code>None</code> for failed articles, making batch processing resilient:</p> <pre><code>pmcids = [\"7114487\", \"3084273\", \"invalid_id\", \"7690653\"]\nsuccessful = []\nfailed = []\n\nfor pmcid in pmcids:\n    data = process_single_pmc(pmcid)\n    if data is None:\n        failed.append(pmcid)\n    else:\n        successful.append(pmcid)\n\nprint(f\"Processed: {len(successful)}, Failed: {len(failed)}\")\n</code></pre>"},{"location":"user-guide/basic-usage/#structured-output","title":"Structured Output","text":"<p>Each article returns a comprehensive dictionary:</p> <pre><code>data = process_single_pmc(\"7114487\")\n\n# Core metadata\nprint(f\"PMC ID: {data['pmc_id']}\")\nprint(f\"Title: {data['title']}\")\nprint(f\"Journal: {data['journal']}\")\nprint(f\"DOI: {data.get('doi', 'N/A')}\")\n\n# Authors\nprint(f\"Authors ({len(data['authors'])}):\")\nfor author in data['authors'][:3]:\n    print(f\"  - {author['First_Name']} {author['Last_Name']}\")\n\n# Content sections\nprint(f\"Sections: {list(data['body'].keys())}\")\nprint(f\"Abstract length: {len(data['abstract'])} characters\")\n\n# Additional data\nprint(f\"Figures: {len(data.get('figures', []))}\")\nprint(f\"Tables: {len(data.get('tables', []))}\")\nprint(f\"References: {len(data.get('references', []))}\")\n</code></pre>"},{"location":"user-guide/basic-usage/#batch-processing-patterns","title":"Batch Processing Patterns","text":""},{"location":"user-guide/basic-usage/#simple-loop-processing","title":"Simple Loop Processing","text":"<pre><code>from pmcgrab.application.processing import process_single_pmc\nfrom pmcgrab.infrastructure.settings import next_email\nimport json\nfrom pathlib import Path\n\ndef process_pmcids(pmcids, output_dir=\"results\"):\n    \"\"\"Process a list of PMC IDs and save results.\"\"\"\n    output_path = Path(output_dir)\n    output_path.mkdir(exist_ok=True)\n\n    results = []\n\n    for pmcid in pmcids:\n        email = next_email()\n        print(f\"Processing PMC{pmcid}...\")\n\n        data = process_single_pmc(pmcid)\n        if data is None:\n            print(f\"  Failed to process PMC{pmcid}\")\n            continue\n\n        # Save individual file\n        output_file = output_path / f\"PMC{pmcid}.json\"\n        with output_file.open('w', encoding='utf-8') as f:\n            json.dump(data, f, indent=2, ensure_ascii=False)\n\n        results.append(data)\n        print(f\"  Saved PMC{pmcid}\")\n\n    return results\n\n# Usage\npmcids = [\"7114487\", \"3084273\", \"7690653\"]\npapers = process_pmcids(pmcids)\nprint(f\"Successfully processed {len(papers)} papers\")\n</code></pre>"},{"location":"user-guide/basic-usage/#with-progress-tracking","title":"With Progress Tracking","text":"<pre><code>from tqdm import tqdm\n\ndef process_with_progress(pmcids, output_dir=\"results\"):\n    \"\"\"Process PMC IDs with progress bar.\"\"\"\n    output_path = Path(output_dir)\n    output_path.mkdir(exist_ok=True)\n\n    successful = 0\n\n    for pmcid in tqdm(pmcids, desc=\"Processing papers\"):\n        data = process_single_pmc(pmcid)\n        if data is not None:\n            output_file = output_path / f\"PMC{pmcid}.json\"\n            with output_file.open('w', encoding='utf-8') as f:\n                json.dump(data, f, indent=2, ensure_ascii=False)\n            successful += 1\n\n    print(f\"Successfully processed {successful}/{len(pmcids)} papers\")\n\n# Usage\nlarge_pmcid_list = [\"7114487\", \"3084273\", \"7690653\", \"5707528\", \"7979870\"]\nprocess_with_progress(large_pmcid_list)\n</code></pre>"},{"location":"user-guide/basic-usage/#command-line-interface","title":"Command Line Interface","text":"<p>Process articles from the command line:</p> <pre><code># Single article\nuv run python -m pmcgrab PMC7114487\n\n# Multiple articles\nuv run python -m pmcgrab PMC7114487 PMC3084273 PMC7690653\n\n# From file\necho -e \"7114487\\n3084273\\n7690653\" &gt; pmcids.txt\nuv run python -m pmcgrab --input-file pmcids.txt --output-dir results/\n\n# With custom settings\nuv run python -m pmcgrab \\\n    --output-dir ./papers \\\n    --workers 4 \\\n    --batch-size 10 \\\n    --email researcher@university.edu \\\n    PMC7114487 PMC3084273\n</code></pre>"},{"location":"user-guide/basic-usage/#output-files","title":"Output Files","text":"<p>PMCGrab creates structured JSON files:</p> <pre><code>{\n  \"pmc_id\": \"7114487\",\n  \"title\": \"Machine learning approaches in cancer research\",\n  \"abstract\": \"Recent advances in machine learning have...\",\n  \"body\": {\n    \"Introduction\": \"Cancer research has evolved significantly...\",\n    \"Methods\": \"We implemented a deep learning framework...\",\n    \"Results\": \"Our model achieved 94.2% accuracy...\",\n    \"Discussion\": \"These findings demonstrate the potential...\"\n  },\n  \"authors\": [\n    {\n      \"First_Name\": \"John\",\n      \"Last_Name\": \"Doe\",\n      \"Affiliation\": \"Cancer Research Institute\"\n    }\n  ],\n  \"journal\": \"Nature Medicine\",\n  \"pub_date\": \"2023-05-15\",\n  \"doi\": \"10.1038/s41591-023-02345-6\",\n  \"figures\": [...],\n  \"tables\": [...],\n  \"references\": [...]\n}\n</code></pre> <p>This structure is optimized for:</p> <ul> <li>Vector databases: Each section can be embedded separately</li> <li>RAG systems: Context-aware retrieval by section</li> <li>Data analysis: Structured access to all article components</li> <li>LLM processing: Clean, section-aware text chunks</li> </ul>"},{"location":"user-guide/basic-usage/#next-steps","title":"Next Steps","text":"<ul> <li>Batch Processing: Advanced parallel processing techniques</li> <li>CLI Reference: Complete command-line documentation</li> <li>Output Format: Detailed JSON schema reference</li> <li>Examples: More real-world usage patterns</li> </ul>"},{"location":"user-guide/batch-processing/","title":"Batch Processing","text":"<p>PMCGrab provides efficient batch processing capabilities for handling large collections of PMC articles.</p>"},{"location":"user-guide/batch-processing/#recommended-approach","title":"Recommended Approach","text":"<p>The primary way to process multiple articles is using the <code>process_single_pmc</code> function in a loop:</p> <pre><code># \u2500\u2500\u2500 examples/run_three_pmcs.py \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\nimport json\nfrom pathlib import Path\n\nfrom pmcgrab.application.processing import process_single_pmc\nfrom pmcgrab.infrastructure.settings import next_email\n\n# The PMC IDs we want to process\nPMC_IDS = [\"7114487\", \"3084273\", \"7690653\", \"5707528\", \"7979870\"]\n\nOUT_DIR = Path(\"pmc_output\")\nOUT_DIR.mkdir(exist_ok=True)\n\nfor pmcid in PMC_IDS:\n    email = next_email()\n    print(f\"\u2022 Fetching PMC{pmcid} using email {email} \u2026\")\n    data = process_single_pmc(pmcid)\n    if data is None:\n        print(f\"  \u21b3 FAILED to parse PMC{pmcid}\")\n        continue\n\n    # Pretty-print a few key fields\n    print(\n        f\"  Title   : {data['title'][:80]}{'\u2026' if len(data['title']) &gt; 80 else ''}\\n\"\n        f\"  Abstract: {data['abstract'][:120]}{'\u2026' if len(data['abstract']) &gt; 120 else ''}\\n\"\n        f\"  Authors : {len(data['authors']) if data['authors'] else 0}\"\n    )\n\n    # Persist full JSON\n    dest = OUT_DIR / f\"PMC{pmcid}.json\"\n    with dest.open(\"w\", encoding=\"utf-8\") as fh:\n        json.dump(data, fh, indent=2, ensure_ascii=False)\n    print(f\"  \u21b3 JSON saved to {dest}\\n\")\n</code></pre>"},{"location":"user-guide/batch-processing/#advanced-batch-processing-patterns","title":"Advanced Batch Processing Patterns","text":""},{"location":"user-guide/batch-processing/#with-error-tracking","title":"With Error Tracking","text":"<pre><code>import json\nfrom pathlib import Path\nfrom pmcgrab.application.processing import process_single_pmc\nfrom pmcgrab.infrastructure.settings import next_email\n\ndef process_with_error_tracking(pmcids, output_dir=\"results\"):\n    \"\"\"Process PMC IDs with comprehensive error tracking.\"\"\"\n    output_path = Path(output_dir)\n    output_path.mkdir(exist_ok=True)\n\n    successful = []\n    failed = []\n\n    for pmcid in pmcids:\n        email = next_email()\n        print(f\"Processing PMC{pmcid}...\")\n\n        try:\n            data = process_single_pmc(pmcid)\n            if data is None:\n                failed.append(pmcid)\n                print(f\"  Failed: No data returned\")\n                continue\n\n            # Save successful result\n            output_file = output_path / f\"PMC{pmcid}.json\"\n            with output_file.open('w', encoding='utf-8') as f:\n                json.dump(data, f, indent=2, ensure_ascii=False)\n\n            successful.append(pmcid)\n            print(f\"  Success: {data['title'][:50]}...\")\n\n        except Exception as e:\n            failed.append(pmcid)\n            print(f\"  Error: {str(e)}\")\n\n    # Save processing summary\n    summary = {\n        'total': len(pmcids),\n        'successful': len(successful),\n        'failed': len(failed),\n        'failed_ids': failed\n    }\n\n    summary_file = output_path / \"processing_summary.json\"\n    with summary_file.open('w', encoding='utf-8') as f:\n        json.dump(summary, f, indent=2)\n\n    print(f\"\\nProcessing complete: {len(successful)}/{len(pmcids)} successful\")\n    return successful, failed\n\n# Usage\npmcids = [\"7114487\", \"3084273\", \"7690653\", \"invalid_id\", \"5707528\"]\nsuccessful, failed = process_with_error_tracking(pmcids)\n</code></pre>"},{"location":"user-guide/batch-processing/#with-progress-tracking","title":"With Progress Tracking","text":"<pre><code>from tqdm import tqdm\nimport json\nfrom pathlib import Path\nfrom pmcgrab.application.processing import process_single_pmc\nfrom pmcgrab.infrastructure.settings import next_email\n\ndef process_with_progress(pmcids, output_dir=\"results\"):\n    \"\"\"Process PMC IDs with progress bar.\"\"\"\n    output_path = Path(output_dir)\n    output_path.mkdir(exist_ok=True)\n\n    successful = 0\n\n    for pmcid in tqdm(pmcids, desc=\"Processing papers\"):\n        email = next_email()\n        data = process_single_pmc(pmcid)\n\n        if data is not None:\n            output_file = output_path / f\"PMC{pmcid}.json\"\n            with output_file.open('w', encoding='utf-8') as f:\n                json.dump(data, f, indent=2, ensure_ascii=False)\n            successful += 1\n            tqdm.write(f\"Success PMC{pmcid}: {data['title'][:40]}...\")\n        else:\n            tqdm.write(f\"Error PMC{pmcid}: Failed to process\")\n\n    print(f\"\\nCompleted: {successful}/{len(pmcids)} papers processed successfully\")\n\n# Usage\nlarge_pmcid_list = [\"7114487\", \"3084273\", \"7690653\", \"5707528\", \"7979870\"]\nprocess_with_progress(large_pmcid_list)\n</code></pre>"},{"location":"user-guide/batch-processing/#reading-pmc-ids-from-files","title":"Reading PMC IDs from Files","text":""},{"location":"user-guide/batch-processing/#from-text-file","title":"From Text File","text":"<pre><code>import json\nfrom pathlib import Path\nfrom pmcgrab.application.processing import process_single_pmc\nfrom pmcgrab.infrastructure.settings import next_email\n\ndef process_from_file(filename, output_dir=\"results\"):\n    \"\"\"Process PMC IDs from a text file.\"\"\"\n    # Read PMC IDs from file (one per line)\n    with open(filename, 'r') as f:\n        pmcids = [line.strip() for line in f if line.strip()]\n\n    print(f\"Read {len(pmcids)} PMC IDs from {filename}\")\n\n    output_path = Path(output_dir)\n    output_path.mkdir(exist_ok=True)\n\n    for pmcid in pmcids:\n        email = next_email()\n        print(f\"Processing PMC{pmcid}...\")\n\n        data = process_single_pmc(pmcid)\n        if data is not None:\n            output_file = output_path / f\"PMC{pmcid}.json\"\n            with output_file.open('w', encoding='utf-8') as f:\n                json.dump(data, f, indent=2, ensure_ascii=False)\n            print(f\"  Saved PMC{pmcid}\")\n        else:\n            print(f\"  Failed PMC{pmcid}\")\n\n# Create example file\nwith open('pmc_ids.txt', 'w') as f:\n    f.write(\"7114487\\n3084273\\n7690653\\n5707528\\n7979870\\n\")\n\n# Process from file\nprocess_from_file('pmc_ids.txt')\n</code></pre>"},{"location":"user-guide/batch-processing/#from-csv-file","title":"From CSV File","text":"<pre><code>import pandas as pd\nimport json\nfrom pathlib import Path\nfrom pmcgrab.application.processing import process_single_pmc\nfrom pmcgrab.infrastructure.settings import next_email\n\ndef process_from_csv(csv_file, pmcid_column='pmcid', output_dir=\"results\"):\n    \"\"\"Process PMC IDs from a CSV file.\"\"\"\n    df = pd.read_csv(csv_file)\n    pmcids = df[pmcid_column].astype(str).tolist()\n\n    print(f\"Read {len(pmcids)} PMC IDs from {csv_file}\")\n\n    output_path = Path(output_dir)\n    output_path.mkdir(exist_ok=True)\n\n    results = []\n\n    for i, pmcid in enumerate(pmcids):\n        email = next_email()\n        print(f\"Processing {i+1}/{len(pmcids)}: PMC{pmcid}...\")\n\n        data = process_single_pmc(pmcid)\n        if data is not None:\n            # Add CSV metadata to the result\n            csv_row = df.iloc[i].to_dict()\n            data['csv_metadata'] = csv_row\n\n            output_file = output_path / f\"PMC{pmcid}.json\"\n            with output_file.open('w', encoding='utf-8') as f:\n                json.dump(data, f, indent=2, ensure_ascii=False)\n\n            results.append(data)\n            print(f\"  Success: {data['title'][:40]}...\")\n        else:\n            print(f\"  Failed to process PMC{pmcid}\")\n\n    return results\n\n# Create example CSV\ncsv_data = {\n    'pmcid': [7114487, 3084273, 7690653],\n    'category': ['cancer', 'ML', 'genomics'],\n    'priority': ['high', 'medium', 'high']\n}\npd.DataFrame(csv_data).to_csv('articles.csv', index=False)\n\n# Process from CSV\nresults = process_from_csv('articles.csv')\n</code></pre>"},{"location":"user-guide/batch-processing/#large-dataset-processing","title":"Large Dataset Processing","text":""},{"location":"user-guide/batch-processing/#chunked-processing","title":"Chunked Processing","text":"<pre><code>import json\nfrom pathlib import Path\nfrom pmcgrab.application.processing import process_single_pmc\nfrom pmcgrab.infrastructure.settings import next_email\n\ndef process_large_dataset(pmcids, output_dir=\"large_dataset\", chunk_size=100):\n    \"\"\"Process very large datasets in chunks.\"\"\"\n    total_chunks = len(pmcids) // chunk_size + (1 if len(pmcids) % chunk_size else 0)\n\n    base_path = Path(output_dir)\n    base_path.mkdir(exist_ok=True)\n\n    overall_stats = {'successful': 0, 'failed': 0}\n\n    for i in range(0, len(pmcids), chunk_size):\n        chunk = pmcids[i:i + chunk_size]\n        chunk_num = i // chunk_size + 1\n\n        print(f\"\\n=== Processing chunk {chunk_num}/{total_chunks} ({len(chunk)} articles) ===\")\n\n        # Create chunk-specific output directory\n        chunk_dir = base_path / f\"chunk_{chunk_num:03d}\"\n        chunk_dir.mkdir(exist_ok=True)\n\n        chunk_stats = {'successful': 0, 'failed': 0, 'failed_ids': []}\n\n        for pmcid in chunk:\n            email = next_email()\n            data = process_single_pmc(pmcid)\n\n            if data is not None:\n                output_file = chunk_dir / f\"PMC{pmcid}.json\"\n                with output_file.open('w', encoding='utf-8') as f:\n                    json.dump(data, f, indent=2, ensure_ascii=False)\n                chunk_stats['successful'] += 1\n                overall_stats['successful'] += 1\n            else:\n                chunk_stats['failed'] += 1\n                chunk_stats['failed_ids'].append(pmcid)\n                overall_stats['failed'] += 1\n\n        # Save chunk summary\n        summary_file = chunk_dir / \"chunk_summary.json\"\n        with summary_file.open('w', encoding='utf-8') as f:\n            json.dump(chunk_stats, f, indent=2)\n\n        print(f\"Chunk {chunk_num} complete: {chunk_stats['successful']} successful, {chunk_stats['failed']} failed\")\n\n    # Save overall summary\n    overall_summary = {\n        'total_articles': len(pmcids),\n        'total_chunks': total_chunks,\n        'chunk_size': chunk_size,\n        **overall_stats,\n        'success_rate': overall_stats['successful'] / len(pmcids) * 100\n    }\n\n    summary_file = base_path / \"overall_summary.json\"\n    with summary_file.open('w', encoding='utf-8') as f:\n        json.dump(overall_summary, f, indent=2)\n\n    print(f\"\\n=== Processing Complete ===\")\n    print(f\"Total: {len(pmcids)} articles\")\n    print(f\"Successful: {overall_stats['successful']}\")\n    print(f\"Failed: {overall_stats['failed']}\")\n    print(f\"Success rate: {overall_summary['success_rate']:.1f}%\")\n\n# Example: process 500 articles in chunks of 50\nlarge_pmcid_list = [str(7000000 + i) for i in range(500)]  # Example IDs\nprocess_large_dataset(large_pmcid_list, chunk_size=50)\n</code></pre>"},{"location":"user-guide/batch-processing/#memory-efficient-processing","title":"Memory-Efficient Processing","text":"<pre><code>import json\nimport gc\nfrom pathlib import Path\nfrom pmcgrab.application.processing import process_single_pmc\nfrom pmcgrab.infrastructure.settings import next_email\n\ndef memory_efficient_processing(pmcids, output_dir=\"memory_efficient\", batch_size=10):\n    \"\"\"Process articles with memory management.\"\"\"\n    output_path = Path(output_dir)\n    output_path.mkdir(exist_ok=True)\n\n    for i in range(0, len(pmcids), batch_size):\n        batch = pmcids[i:i + batch_size]\n        batch_num = i // batch_size + 1\n\n        print(f\"Processing batch {batch_num}: {len(batch)} articles\")\n\n        for pmcid in batch:\n            email = next_email()\n            data = process_single_pmc(pmcid)\n\n            if data is not None:\n                # Save immediately and clear from memory\n                output_file = output_path / f\"PMC{pmcid}.json\"\n                with output_file.open('w', encoding='utf-8') as f:\n                    json.dump(data, f, indent=2, ensure_ascii=False)\n                print(f\"  Saved PMC{pmcid}\")\n\n                # Clear data from memory\n                del data\n            else:\n                print(f\"  Failed PMC{pmcid}\")\n\n        # Force garbage collection after each batch\n        gc.collect()\n        print(f\"Batch {batch_num} complete, memory cleared\")\n\n# Usage\nlarge_list = [str(7000000 + i) for i in range(100)]\nmemory_efficient_processing(large_list, batch_size=10)\n</code></pre>"},{"location":"user-guide/batch-processing/#resumable-processing","title":"Resumable Processing","text":""},{"location":"user-guide/batch-processing/#resume-from-previous-run","title":"Resume from Previous Run","text":"<pre><code>import json\nfrom pathlib import Path\nfrom pmcgrab.application.processing import process_single_pmc\nfrom pmcgrab.infrastructure.settings import next_email\n\ndef resumable_processing(pmcids, output_dir=\"resumable_output\"):\n    \"\"\"Resume processing from where it left off.\"\"\"\n    output_path = Path(output_dir)\n    output_path.mkdir(exist_ok=True)\n\n    # Check what's already been processed\n    processed_files = list(output_path.glob(\"PMC*.json\"))\n    processed_ids = [f.stem.replace('PMC', '') for f in processed_files]\n\n    # Filter out already processed IDs\n    remaining_ids = [pmcid for pmcid in pmcids if pmcid not in processed_ids]\n\n    print(f\"Found {len(processed_ids)} already processed articles\")\n    print(f\"Remaining to process: {len(remaining_ids)}\")\n\n    if not remaining_ids:\n        print(\"All articles already processed!\")\n        return\n\n    # Process remaining articles\n    for pmcid in remaining_ids:\n        email = next_email()\n        print(f\"Processing PMC{pmcid}...\")\n\n        data = process_single_pmc(pmcid)\n        if data is not None:\n            output_file = output_path / f\"PMC{pmcid}.json\"\n            with output_file.open('w', encoding='utf-8') as f:\n                json.dump(data, f, indent=2, ensure_ascii=False)\n            print(f\"  Saved PMC{pmcid}\")\n        else:\n            print(f\"  Failed PMC{pmcid}\")\n\n    print(\"Processing complete!\")\n\n# Usage - can be run multiple times safely\nall_pmcids = [\"7114487\", \"3084273\", \"7690653\", \"5707528\", \"7979870\"]\nresumable_processing(all_pmcids)\n</code></pre>"},{"location":"user-guide/batch-processing/#command-line-batch-processing","title":"Command Line Batch Processing","text":"<p>For command-line batch processing, use the built-in CLI:</p> <pre><code># From individual IDs\nuv run python -m pmcgrab PMC7114487 PMC3084273 PMC7690653\n\n# From file\necho -e \"7114487\\n3084273\\n7690653\" &gt; pmcids.txt\nuv run python -m pmcgrab --input-file pmcids.txt --output-dir batch_results/\n\n# With custom settings\nuv run python -m pmcgrab \\\n    --input-file pmcids.txt \\\n    --output-dir ./results \\\n    --workers 4 \\\n    --batch-size 10 \\\n    --max-retries 2 \\\n    --email researcher@university.edu\n</code></pre>"},{"location":"user-guide/batch-processing/#best-practices","title":"Best Practices","text":""},{"location":"user-guide/batch-processing/#production-ready-processing","title":"Production-Ready Processing","text":"<pre><code>import json\nimport logging\nfrom datetime import datetime\nfrom pathlib import Path\nfrom pmcgrab.application.processing import process_single_pmc\nfrom pmcgrab.infrastructure.settings import next_email\n\ndef production_batch_processing(pmcids, output_dir=\"production_output\"):\n    \"\"\"Production-ready batch processing with logging.\"\"\"\n\n    # Set up logging\n    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n    log_file = f\"pmcgrab_batch_{timestamp}.log\"\n\n    logging.basicConfig(\n        level=logging.INFO,\n        format='%(asctime)s - %(levelname)s - %(message)s',\n        handlers=[\n            logging.FileHandler(log_file),\n            logging.StreamHandler()\n        ]\n    )\n\n    logger = logging.getLogger(__name__)\n    logger.info(f\"Starting batch processing of {len(pmcids)} articles\")\n\n    # Create timestamped output directory\n    output_path = Path(output_dir) / f\"batch_{timestamp}\"\n    output_path.mkdir(parents=True, exist_ok=True)\n\n    stats = {'successful': 0, 'failed': 0, 'failed_ids': []}\n\n    try:\n        for i, pmcid in enumerate(pmcids, 1):\n            logger.info(f\"Processing {i}/{len(pmcids)}: PMC{pmcid}\")\n\n            email = next_email()\n            data = process_single_pmc(pmcid)\n\n            if data is not None:\n                output_file = output_path / f\"PMC{pmcid}.json\"\n                with output_file.open('w', encoding='utf-8') as f:\n                    json.dump(data, f, indent=2, ensure_ascii=False)\n\n                stats['successful'] += 1\n                logger.info(f\"Success: {data['title'][:50]}...\")\n            else:\n                stats['failed'] += 1\n                stats['failed_ids'].append(pmcid)\n                logger.warning(f\"Failed to process PMC{pmcid}\")\n\n        # Save final summary\n        summary_file = output_path / \"processing_summary.json\"\n        with summary_file.open('w', encoding='utf-8') as f:\n            json.dump(stats, f, indent=2)\n\n        success_rate = stats['successful'] / len(pmcids) * 100\n        logger.info(f\"Batch processing completed: {stats['successful']}/{len(pmcids)} successful ({success_rate:.1f}%)\")\n        logger.info(f\"Output directory: {output_path}\")\n        logger.info(f\"Log file: {log_file}\")\n\n    except Exception as e:\n        logger.error(f\"Batch processing failed: {e}\")\n        raise\n\n    return stats\n\n# Run production processing\npmcids = [\"7114487\", \"3084273\", \"7690653\", \"5707528\", \"7979870\"]\nresults = production_batch_processing(pmcids)\n</code></pre> <p>This approach provides robust, scalable batch processing while maintaining simplicity and reliability.</p>"},{"location":"user-guide/cli/","title":"Command Line Interface","text":"<p>PMCGrab provides a powerful command-line interface for batch processing and article retrieval.</p>"},{"location":"user-guide/cli/#basic-usage","title":"Basic Usage","text":""},{"location":"user-guide/cli/#single-article","title":"Single Article","text":"<pre><code># Process a single PMC article\nuv run python -m pmcgrab --pmcids 7181753\n\n# Specify email (required by NCBI)\nuv run python -m pmcgrab --pmcids --email your-email@example.com 7181753\n</code></pre>"},{"location":"user-guide/cli/#multiple-articles","title":"Multiple Articles","text":"<pre><code># Process multiple articles\nuv run python -m pmcgrab --pmcids 7181753 3539614 5454911\n\n# From a file (one PMC ID per line)\nuv run python -m pmcgrab --pmcids --input-file pmc_ids.txt\n</code></pre>"},{"location":"user-guide/cli/#command-options","title":"Command Options","text":""},{"location":"user-guide/cli/#output-configuration","title":"Output Configuration","text":"<pre><code># Custom output directory\nuv run python -m pmcgrab --pmcids --output-dir ./results 7181753\n\n# Create timestamped directory\nuv run python -m pmcgrab --pmcids --output-dir ./results_$(date +%Y%m%d) 7181753\n</code></pre>"},{"location":"user-guide/cli/#performance-options","title":"Performance Options","text":"<pre><code># Parallel processing\nuv run python -m pmcgrab --pmcids --workers 8 7181753 3539614\n\n# Batch size configuration\nuv run python -m pmcgrab --pmcids --batch-size 20 --workers 4 7181753 3539614\n\n# Timeout settings\nuv run python -m pmcgrab --pmcids --timeout 60 7181753\n</code></pre>"},{"location":"user-guide/cli/#error-handling","title":"Error Handling","text":"<pre><code># Retry configuration\nuv run python -m pmcgrab --max-retries 5 7181753\n\n# Verbose output\nuv run python -m pmcgrab --verbose 7181753\n\n# Suppress warnings\nuv run python -m pmcgrab --quiet 7181753\n</code></pre>"},{"location":"user-guide/cli/#complete-example","title":"Complete Example","text":"<pre><code>uv run python -m pmcgrab \\\n    --email your-email@example.com \\\n    --output-dir ./pmc_results \\\n    --workers 8 \\\n    --batch-size 25 \\\n    --max-retries 3 \\\n    --timeout 60 \\\n    --verbose \\\n    7181753 3539614 5454911\n</code></pre>"},{"location":"user-guide/cli/#input-files","title":"Input Files","text":""},{"location":"user-guide/cli/#text-file-format","title":"Text File Format","text":"<p>Create <code>pmc_ids.txt</code>:</p> <pre><code>7181753\n3539614\n5454911\n8378853\n7462677\n</code></pre> <p>Then run:</p> <pre><code>uv run python -m pmcgrab --input-file pmc_ids.txt --email your-email@example.com\n</code></pre>"},{"location":"user-guide/cli/#csv-input","title":"CSV Input","text":"<p>For CSV files with PMC IDs in a specific column:</p> <pre><code># If PMC IDs are in 'pmcid' column\nuv run python -m pmcgrab --input-csv articles.csv --pmcid-column pmcid\n\n# If PMC IDs are in 'id' column\nuv run python -m pmcgrab --input-csv data.csv --pmcid-column id\n</code></pre>"},{"location":"user-guide/cli/#output-files","title":"Output Files","text":"<p>The CLI creates several output files:</p>"},{"location":"user-guide/cli/#individual-article-files","title":"Individual Article Files","text":"<pre><code>output_directory/\n\u251c\u2500\u2500 7181753.json      # Individual article data\n\u251c\u2500\u2500 3539614.json\n\u2514\u2500\u2500 5454911.json\n</code></pre>"},{"location":"user-guide/cli/#summary-files","title":"Summary Files","text":"<pre><code>output_directory/\n\u251c\u2500\u2500 processing_summary.json    # Processing statistics\n\u251c\u2500\u2500 failed_pmcids.txt         # Failed PMC IDs\n\u2514\u2500\u2500 processing.log            # Detailed log (if --log-file used)\n</code></pre>"},{"location":"user-guide/cli/#environment-variables","title":"Environment Variables","text":"<p>Set default values using environment variables:</p> <pre><code>export PMCGRAB_EMAIL=\"your-email@example.com\"\nexport PMCGRAB_OUTPUT_DIR=\"./default_output\"\nexport PMCGRAB_WORKERS=8\nexport PMCGRAB_BATCH_SIZE=20\nexport PMCGRAB_TIMEOUT=60\nexport PMCGRAB_MAX_RETRIES=3\n\n# Now you can run with defaults\nuv run python -m pmcgrab 7181753\n</code></pre>"},{"location":"user-guide/cli/#advanced-usage","title":"Advanced Usage","text":""},{"location":"user-guide/cli/#filtering-and-validation","title":"Filtering and Validation","text":"<pre><code># Validate XML structure\nuv run python -m pmcgrab --validate 7181753\n\n# Skip validation for speed\nuv run python -m pmcgrab --no-validate 7181753\n\n# Download and cache XML files\nuv run python -m pmcgrab --download --cache-dir ./xml_cache 7181753\n</code></pre>"},{"location":"user-guide/cli/#resume-processing","title":"Resume Processing","text":"<pre><code># Resume from previous failed run\nuv run python -m pmcgrab --resume --input-dir ./previous_output 7181753 3539614\n\n# Or resume from failed IDs file\nuv run python -m pmcgrab --input-file ./previous_output/failed_pmcids.txt\n</code></pre>"},{"location":"user-guide/cli/#logging-options","title":"Logging Options","text":"<pre><code># Enable detailed logging\nuv run python -m pmcgrab --verbose --log-file processing.log 7181753\n\n# Different log levels\nuv run python -m pmcgrab --log-level DEBUG 7181753\nuv run python -m pmcgrab --log-level WARNING 7181753\n</code></pre>"},{"location":"user-guide/cli/#batch-processing-examples","title":"Batch Processing Examples","text":""},{"location":"user-guide/cli/#small-scale-100-articles","title":"Small Scale (&lt; 100 articles)","text":"<pre><code>uv run python -m pmcgrab \\\n    --input-file small_list.txt \\\n    --workers 4 \\\n    --batch-size 10 \\\n    --email your-email@example.com\n</code></pre>"},{"location":"user-guide/cli/#medium-scale-100-1000-articles","title":"Medium Scale (100-1000 articles)","text":"<pre><code>uv run python -m pmcgrab \\\n    --input-file medium_list.txt \\\n    --workers 8 \\\n    --batch-size 25 \\\n    --max-retries 3 \\\n    --timeout 45 \\\n    --verbose \\\n    --email your-email@example.com\n</code></pre>"},{"location":"user-guide/cli/#large-scale-1000-articles","title":"Large Scale (1000+ articles)","text":"<pre><code>uv run python -m pmcgrab \\\n    --input-file large_list.txt \\\n    --workers 12 \\\n    --batch-size 50 \\\n    --max-retries 5 \\\n    --timeout 90 \\\n    --cache-dir ./xml_cache \\\n    --log-file large_processing.log \\\n    --email your-email@example.com\n</code></pre>"},{"location":"user-guide/cli/#error-handling_1","title":"Error Handling","text":""},{"location":"user-guide/cli/#common-exit-codes","title":"Common Exit Codes","text":"<ul> <li><code>0</code>: Success</li> <li><code>1</code>: General error</li> <li><code>2</code>: Invalid arguments</li> <li><code>3</code>: Network error</li> <li><code>4</code>: File not found</li> <li><code>5</code>: Permission error</li> </ul>"},{"location":"user-guide/cli/#handling-failures","title":"Handling Failures","text":"<pre><code># Run with error handling\nuv run python -m pmcgrab 7181753 3539614\nEXIT_CODE=$?\n\nif [ $EXIT_CODE -eq 0 ]; then\n    echo \"Processing completed successfully\"\nelif [ $EXIT_CODE -eq 3 ]; then\n    echo \"Network error - check connection and retry\"\nelse\n    echo \"Processing failed with exit code $EXIT_CODE\"\nfi\n</code></pre>"},{"location":"user-guide/cli/#retry-failed-articles","title":"Retry Failed Articles","text":"<pre><code># Initial processing\nuv run python -m pmcgrab --input-file all_ids.txt --output-dir ./results\n\n# Retry failed articles\nif [ -f ./results/failed_pmcids.txt ]; then\n    echo \"Retrying failed articles...\"\n    uv run python -m pmcgrab \\\n        --input-file ./results/failed_pmcids.txt \\\n        --output-dir ./results \\\n        --max-retries 5 \\\n        --timeout 120\nfi\n</code></pre>"},{"location":"user-guide/cli/#performance-tuning","title":"Performance Tuning","text":""},{"location":"user-guide/cli/#network-optimization","title":"Network Optimization","text":"<pre><code># For slow networks\nuv run python -m pmcgrab \\\n    --workers 2 \\\n    --batch-size 5 \\\n    --timeout 120 \\\n    --max-retries 10 \\\n    7181753\n\n# For fast networks\nuv run python -m pmcgrab \\\n    --workers 16 \\\n    --batch-size 50 \\\n    --timeout 30 \\\n    --max-retries 2 \\\n    7181753\n</code></pre>"},{"location":"user-guide/cli/#memory-optimization","title":"Memory Optimization","text":"<pre><code># For memory-constrained systems\nuv run python -m pmcgrab \\\n    --workers 2 \\\n    --batch-size 5 \\\n    --no-cache \\\n    7181753\n\n# For high-memory systems\nuv run python -m pmcgrab \\\n    --workers 16 \\\n    --batch-size 100 \\\n    --cache-dir ./large_cache \\\n    7181753\n</code></pre>"},{"location":"user-guide/cli/#integration-with-shell-scripts","title":"Integration with Shell Scripts","text":""},{"location":"user-guide/cli/#bash-script-example","title":"Bash Script Example","text":"<pre><code>#!/bin/bash\n\n# PMCGrab batch processing script\nEMAIL=\"your-email@example.com\"\nINPUT_FILE=\"pmc_ids.txt\"\nOUTPUT_DIR=\"./batch_$(date +%Y%m%d_%H%M%S)\"\nLOG_FILE=\"processing_$(date +%Y%m%d_%H%M%S).log\"\n\necho \"Starting PMCGrab batch processing...\"\necho \"Input file: $INPUT_FILE\"\necho \"Output directory: $OUTPUT_DIR\"\necho \"Log file: $LOG_FILE\"\n\nuv run python -m pmcgrab \\\n    --input-file \"$INPUT_FILE\" \\\n    --output-dir \"$OUTPUT_DIR\" \\\n    --email \"$EMAIL\" \\\n    --workers 8 \\\n    --batch-size 20 \\\n    --max-retries 3 \\\n    --verbose \\\n    --log-file \"$LOG_FILE\"\n\nEXIT_CODE=$?\n\nif [ $EXIT_CODE -eq 0 ]; then\n    echo \"Processing completed successfully!\"\n    echo \"Results in: $OUTPUT_DIR\"\n    echo \"Log file: $LOG_FILE\"\nelse\n    echo \"Processing failed with exit code: $EXIT_CODE\"\n    echo \"Check log file: $LOG_FILE\"\n    exit $EXIT_CODE\nfi\n</code></pre>"},{"location":"user-guide/cli/#powershell-script-example","title":"PowerShell Script Example","text":"<pre><code># PMCGrab batch processing script for Windows\n$EMAIL = \"your-email@example.com\"\n$INPUT_FILE = \"pmc_ids.txt\"\n$OUTPUT_DIR = \"./batch_$(Get-Date -Format 'yyyyMMdd_HHmmss')\"\n$LOG_FILE = \"processing_$(Get-Date -Format 'yyyyMMdd_HHmmss').log\"\n\nWrite-Host \"Starting PMCGrab batch processing...\"\nWrite-Host \"Input file: $INPUT_FILE\"\nWrite-Host \"Output directory: $OUTPUT_DIR\"\nWrite-Host \"Log file: $LOG_FILE\"\n\nuv run python -m pmcgrab `\n    --input-file $INPUT_FILE `\n    --output-dir $OUTPUT_DIR `\n    --email $EMAIL `\n    --workers 8 `\n    --batch-size 20 `\n    --max-retries 3 `\n    --verbose `\n    --log-file $LOG_FILE\n\nif ($LASTEXITCODE -eq 0) {\n    Write-Host \"Processing completed successfully!\" -ForegroundColor Green\n    Write-Host \"Results in: $OUTPUT_DIR\"\n    Write-Host \"Log file: $LOG_FILE\"\n} else {\n    Write-Host \"Processing failed with exit code: $LASTEXITCODE\" -ForegroundColor Red\n    Write-Host \"Check log file: $LOG_FILE\"\n    exit $LASTEXITCODE\n}\n</code></pre>"},{"location":"user-guide/cli/#help-and-documentation","title":"Help and Documentation","text":""},{"location":"user-guide/cli/#get-help","title":"Get Help","text":"<pre><code># Show help message\nuv run python -m pmcgrab --help\n\n# Show version\nuv run python -m pmcgrab --version\n\n# Show configuration\nuv run python -m pmcgrab --show-config\n</code></pre>"},{"location":"user-guide/cli/#all-available-options","title":"All Available Options","text":"<pre><code>Usage: uv run python -m pmcgrab [OPTIONS] [PMCIDS...]\n\nOptions:\n  --email TEXT                    Contact email for NCBI API (required)\n  --output-dir TEXT              Output directory (default: ./pmc_output)\n  --input-file TEXT              File containing PMC IDs (one per line)\n  --input-csv TEXT               CSV file containing PMC IDs\n  --pmcid-column TEXT            Column name for PMC IDs in CSV (default: pmcid)\n  --workers INTEGER              Number of parallel workers (default: 4)\n  --batch-size INTEGER           Batch size for processing (default: 10)\n  --max-retries INTEGER          Maximum retry attempts (default: 3)\n  --timeout INTEGER              Request timeout in seconds (default: 30)\n  --validate / --no-validate     Validate XML structure (default: True)\n  --download / --no-download     Download and cache XML files (default: False)\n  --cache-dir TEXT               Directory for caching XML files\n  --verbose / --quiet            Enable/disable verbose output (default: False)\n  --log-file TEXT                Log file path\n  --log-level TEXT               Log level (DEBUG, INFO, WARNING, ERROR)\n  --resume                       Resume from previous failed run\n  --input-dir TEXT               Input directory for resume mode\n  --version                      Show version and exit\n  --help                         Show this message and exit\n</code></pre> <p>This comprehensive CLI guide should help you use PMCGrab effectively from the command line for any scale of processing.</p>"},{"location":"user-guide/output-format/","title":"Output Format","text":"<p>PMCGrab produces structured JSON output optimized for AI and machine learning applications.</p>"},{"location":"user-guide/output-format/#json-structure-overview","title":"JSON Structure Overview","text":"<p>Each processed PMC article returns a comprehensive dictionary with the following structure:</p> <pre><code>{\n  \"pmc_id\": \"7114487\",\n  \"title\": \"Machine learning approaches in cancer research\",\n  \"abstract\": \"Recent advances in machine learning have revolutionized...\",\n  \"authors\": [...],\n  \"body\": {...},\n  \"journal\": \"Nature Medicine\",\n  \"pub_date\": \"2023-05-15\",\n  \"doi\": \"10.1038/s41591-023-02345-6\",\n  \"figures\": [...],\n  \"tables\": [...],\n  \"references\": [...]\n}\n</code></pre>"},{"location":"user-guide/output-format/#complete-example","title":"Complete Example","text":"<p>Here's a real example of the JSON structure returned by <code>process_single_pmc</code>:</p> <pre><code>{\n  \"pmc_id\": \"7114487\",\n  \"title\": \"Machine learning approaches in cancer research: A systematic review\",\n  \"abstract\": \"Recent advances in machine learning have revolutionized the field of cancer research, enabling more accurate diagnosis, prognosis, and treatment selection. This systematic review examines current applications and future prospects.\",\n  \"authors\": [\n    {\n      \"First_Name\": \"John\",\n      \"Last_Name\": \"Doe\",\n      \"Affiliation\": \"Cancer Research Institute, University of Science\"\n    },\n    {\n      \"First_Name\": \"Jane\",\n      \"Last_Name\": \"Smith\",\n      \"Affiliation\": \"Department of Oncology, Medical Center\"\n    }\n  ],\n  \"body\": {\n    \"Introduction\": \"Cancer remains one of the leading causes of death worldwide...\",\n    \"Methods\": \"We conducted a systematic review following PRISMA guidelines...\",\n    \"Results\": \"Our analysis identified 127 studies that met inclusion criteria...\",\n    \"Discussion\": \"The findings demonstrate significant potential for ML in cancer care...\",\n    \"Conclusion\": \"Machine learning represents a transformative technology...\"\n  },\n  \"journal\": \"Nature Medicine\",\n  \"pub_date\": \"2023-05-15\",\n  \"doi\": \"10.1038/s41591-023-02345-6\",\n  \"figures\": [\n    {\n      \"id\": \"fig1\",\n      \"caption\": \"Overview of machine learning applications in cancer research\",\n      \"url\": \"https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7114487/bin/fig1.jpg\"\n    }\n  ],\n  \"tables\": [\n    {\n      \"id\": \"table1\",\n      \"caption\": \"Summary of studies included in systematic review\",\n      \"content\": \"...\"\n    }\n  ],\n  \"references\": [\n    {\n      \"id\": \"ref1\",\n      \"citation\": \"Smith J, et al. Deep learning for cancer diagnosis. Nature. 2022;123:456-789.\"\n    }\n  ]\n}\n</code></pre>"},{"location":"user-guide/output-format/#field-descriptions","title":"Field Descriptions","text":""},{"location":"user-guide/output-format/#core-metadata","title":"Core Metadata","text":"Field Type Description <code>pmc_id</code> string PubMed Central identifier (without \"PMC\" prefix) <code>title</code> string Complete article title <code>abstract</code> string Article abstract text <code>journal</code> string Journal name <code>pub_date</code> string Publication date (ISO format) <code>doi</code> string Digital Object Identifier"},{"location":"user-guide/output-format/#authors-array","title":"Authors Array","text":"<pre><code>{\n  \"authors\": [\n    {\n      \"First_Name\": \"John\",\n      \"Last_Name\": \"Doe\",\n      \"Affiliation\": \"University Name\"\n    }\n  ]\n}\n</code></pre> <p>Each author object contains:</p> <ul> <li><code>First_Name</code>: Author's first name</li> <li><code>Last_Name</code>: Author's last name</li> <li><code>Affiliation</code>: Institutional affiliation (when available)</li> </ul>"},{"location":"user-guide/output-format/#body-sections","title":"Body Sections","text":"<pre><code>{\n  \"body\": {\n    \"Introduction\": \"The introduction section content...\",\n    \"Methods\": \"The methods section content...\",\n    \"Results\": \"The results section content...\",\n    \"Discussion\": \"The discussion section content...\",\n    \"Conclusion\": \"The conclusion section content...\"\n  }\n}\n</code></pre> <p>Common section names include:</p> <ul> <li>Introduction / Background</li> <li>Methods / Materials and Methods</li> <li>Results</li> <li>Discussion</li> <li>Conclusion</li> <li>References (when included in body)</li> </ul>"},{"location":"user-guide/output-format/#figures-array","title":"Figures Array","text":"<pre><code>{\n  \"figures\": [\n    {\n      \"id\": \"fig1\",\n      \"caption\": \"Description of the figure\",\n      \"url\": \"https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7114487/bin/fig1.jpg\"\n    }\n  ]\n}\n</code></pre>"},{"location":"user-guide/output-format/#tables-array","title":"Tables Array","text":"<pre><code>{\n  \"tables\": [\n    {\n      \"id\": \"table1\",\n      \"caption\": \"Table description\",\n      \"content\": \"Table content when extractable\"\n    }\n  ]\n}\n</code></pre>"},{"location":"user-guide/output-format/#references-array","title":"References Array","text":"<pre><code>{\n  \"references\": [\n    {\n      \"id\": \"ref1\",\n      \"citation\": \"Complete citation text\"\n    }\n  ]\n}\n</code></pre>"},{"location":"user-guide/output-format/#usage-examples","title":"Usage Examples","text":""},{"location":"user-guide/output-format/#accessing-article-data","title":"Accessing Article Data","text":"<pre><code>from pmcgrab.application.processing import process_single_pmc\n\ndata = process_single_pmc(\"7114487\")\n\nif data:\n    # Basic information\n    print(f\"Title: {data['title']}\")\n    print(f\"Journal: {data['journal']}\")\n    print(f\"Authors: {len(data['authors'])}\")\n\n    # Content sections\n    print(f\"Available sections: {list(data['body'].keys())}\")\n\n    # Access specific sections\n    if 'Introduction' in data['body']:\n        intro = data['body']['Introduction']\n        print(f\"Introduction (first 200 chars): {intro[:200]}...\")\n\n    # Additional content\n    print(f\"Figures: {len(data.get('figures', []))}\")\n    print(f\"Tables: {len(data.get('tables', []))}\")\n    print(f\"References: {len(data.get('references', []))}\")\n</code></pre>"},{"location":"user-guide/output-format/#processing-multiple-articles","title":"Processing Multiple Articles","text":"<pre><code># \u2500\u2500\u2500 Process Multiple Articles \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\nimport json\nfrom pathlib import Path\nfrom pmcgrab.application.processing import process_single_pmc\nfrom pmcgrab.infrastructure.settings import next_email\n\nPMC_IDS = [\"7114487\", \"3084273\", \"7690653\"]\nOUTPUT_DIR = Path(\"articles\")\nOUTPUT_DIR.mkdir(exist_ok=True)\n\nfor pmcid in PMC_IDS:\n    email = next_email()\n    data = process_single_pmc(pmcid)\n\n    if data:\n        # Save complete JSON\n        output_file = OUTPUT_DIR / f\"PMC{pmcid}.json\"\n        with output_file.open('w', encoding='utf-8') as f:\n            json.dump(data, f, indent=2, ensure_ascii=False)\n\n        print(f\"Saved PMC{pmcid}: {data['title'][:50]}...\")\n    else:\n        print(f\"Failed to process PMC{pmcid}\")\n</code></pre>"},{"location":"user-guide/output-format/#aiml-integration","title":"AI/ML Integration","text":""},{"location":"user-guide/output-format/#vector-database-preparation","title":"Vector Database Preparation","text":"<pre><code>def prepare_for_vector_db(data):\n    \"\"\"Prepare article data for vector database ingestion.\"\"\"\n    chunks = []\n\n    # Add title and abstract as separate chunks\n    chunks.append({\n        'content': data['title'],\n        'metadata': {\n            'pmc_id': data['pmc_id'],\n            'type': 'title',\n            'journal': data['journal']\n        }\n    })\n\n    chunks.append({\n        'content': data['abstract'],\n        'metadata': {\n            'pmc_id': data['pmc_id'],\n            'type': 'abstract',\n            'journal': data['journal']\n        }\n    })\n\n    # Add each body section as a chunk\n    for section_name, content in data['body'].items():\n        chunks.append({\n            'content': content,\n            'metadata': {\n                'pmc_id': data['pmc_id'],\n                'type': 'section',\n                'section': section_name,\n                'journal': data['journal']\n            }\n        })\n\n    return chunks\n\n# Usage\ndata = process_single_pmc(\"7114487\")\nif data:\n    vector_chunks = prepare_for_vector_db(data)\n    print(f\"Created {len(vector_chunks)} chunks for vector database\")\n</code></pre>"},{"location":"user-guide/output-format/#rag-system-integration","title":"RAG System Integration","text":"<pre><code>def create_rag_documents(pmcids):\n    \"\"\"Create documents for RAG system.\"\"\"\n    documents = []\n\n    for pmcid in pmcids:\n        data = process_single_pmc(pmcid)\n        if data:\n            # Combine sections into full text\n            full_text = f\"{data['title']}\\n\\n{data['abstract']}\\n\\n\"\n            full_text += \"\\n\\n\".join([\n                f\"{section}: {content}\"\n                for section, content in data['body'].items()\n            ])\n\n            documents.append({\n                'id': f\"PMC{pmcid}\",\n                'text': full_text,\n                'metadata': {\n                    'title': data['title'],\n                    'journal': data['journal'],\n                    'authors': [f\"{a['First_Name']} {a['Last_Name']}\" for a in data['authors']],\n                    'pub_date': data.get('pub_date'),\n                    'doi': data.get('doi')\n                }\n            })\n\n    return documents\n\n# Usage\npmcids = [\"7114487\", \"3084273\", \"7690653\"]\nrag_docs = create_rag_documents(pmcids)\n</code></pre>"},{"location":"user-guide/output-format/#file-output","title":"File Output","text":""},{"location":"user-guide/output-format/#individual-json-files","title":"Individual JSON Files","text":"<p>When using the standard processing pattern, each article is saved as a separate JSON file:</p> <pre><code>pmc_output/\n\u251c\u2500\u2500 PMC7114487.json\n\u251c\u2500\u2500 PMC3084273.json\n\u251c\u2500\u2500 PMC7690653.json\n\u251c\u2500\u2500 PMC5707528.json\n\u2514\u2500\u2500 PMC7979870.json\n</code></pre>"},{"location":"user-guide/output-format/#batch-summary","title":"Batch Summary","text":"<p>You can also create summary files for batch processing:</p> <pre><code>import json\nfrom pathlib import Path\n\ndef save_batch_summary(results, output_dir):\n    \"\"\"Save a summary of batch processing results.\"\"\"\n    summary = {\n        'total_processed': len(results),\n        'articles': []\n    }\n\n    for pmcid, data in results:\n        if data:\n            summary['articles'].append({\n                'pmc_id': pmcid,\n                'title': data['title'],\n                'journal': data['journal'],\n                'authors_count': len(data['authors']),\n                'sections': list(data['body'].keys()),\n                'word_count': sum(len(content.split()) for content in data['body'].values())\n            })\n\n    summary_file = Path(output_dir) / \"batch_summary.json\"\n    with summary_file.open('w', encoding='utf-8') as f:\n        json.dump(summary, f, indent=2, ensure_ascii=False)\n\n    return summary\n\n# Usage with processing results\nresults = [(pmcid, process_single_pmc(pmcid)) for pmcid in PMC_IDS]\nvalid_results = [(pmcid, data) for pmcid, data in results if data is not None]\nsummary = save_batch_summary(valid_results, \"pmc_output\")\n</code></pre> <p>This structured JSON format provides everything needed for modern AI/ML workflows while maintaining human readability and programmatic access.</p>"}]}